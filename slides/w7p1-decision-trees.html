<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Decision Trees</title>
    <meta charset="utf-8" />
    <meta name="author" content="Daniel Anderson" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uo.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uo-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/hygge.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Decision Trees
## An introduction
### Daniel Anderson
### Week 7, Class 1

---




# Agenda 

* Overview of CART trees
* Finding an optimal tree - complexity parameter
* Feature interpretation (quickly)

---
# Overview
* Non-parametric (do not make any distributional assumptions)

* Use splitting rules to divide features into non-overlapping regions, where the cases within each region are similar

* Basically the stepping stone for more complex models - generally don't work great on their own.

---
# Classification
* Decision trees are often easiest to think of, initially, through a classification problem
* Think about the titanic dataset - did passengers aboard survive?

---
# An example from the titanic

![](https://supchains.com/wp-content/uploads/2017/11/Titanic_Survival_Decison_Tree_SVG.png)

---
# Some terminology
![](https://bradleyboehmke.github.io/HOML/images/decision-tree-terminology.png)

Note the leaf node is also called the terminal node

---
# Splitting rules
* .red[C]lassification .red[a]nd .red[r]egression .red[t]rees (CART)

  - Partition training data into homogeneous subgroups through recursive splitting (yes/no) until some criterion is reached 
  - Recursive because each split depends on prior splits

--

* At each node, find the "best" partition
  - search all possible splits on all possible variables

--

* How to define best?
  - Regression
      + SSE: `\(\Sigma_{R1}(y_i - c_1)^2 + \Sigma_{R2}(y_i - c_2)^2\)`
        * `\(c\)` starts as a constant and is updated, `\(R\)` is the region
  - Classification
      + Cross-entropy or Gini index (default)

---
# Gini index
Default measure of lack of fit used by `rpart`. For a two class situation:

$$
D_i = 1 - P(c_1)^2 - P(c_2)^2
$$

where `\(P(c_1)\)` and `\(P(c_2)\)` are the probabilities of being in Class 1 or 2, respectively, for node `\(i\)`

For a multi-class solution

$$
D_i = 1 - \Sigma(p_i)^2
$$

So
* When `\(D = 0\)`, the node is "pure" (perfect classification)
* When `\(D = 0.5\)`, the node is random (flip a coin)


---
# A couple examples
* Say your terminal node has 75%  in one class, for a binary decision. The Gini index would be

.left[
$$
`\begin{aligned}
D &amp;= 1 - (0.75^2 + 0.25^2) \\\
D &amp;= 1 - (0.5625 + 0.0625) \\\
D &amp;= 1 - 0.625 \\\
D &amp;= 0.375
\end{aligned}`
$$

]

---
# 90%

$$
`\begin{aligned}
D &amp;= 1 - (0.90^2 + 0.10^2) \\
D &amp;= 1 - (0.81 + 0.01) \\
D &amp;= 1 - 0.82 \\
D &amp;= 0.18
\end{aligned}`
$$

--
### Take home message - lower values mean better classifications


---
background-image: url(https://bradleyboehmke.github.io/HOML/07-decision-trees_files/figure-html/decision-stump-1.png)
background-size:cover

# Visualizing splits

---
background-image: url(https://bradleyboehmke.github.io/HOML/07-decision-trees_files/figure-html/decision-stump-2.png)
background-size:cover


---
# Replicating the book
### Generate some data

```r
n &lt;- 200 # number of data points
x &lt;- seq(0, 3.5, length.out = n)
a &lt;- 5
b &lt;- 2
error &lt;- rnorm(n)
amp &lt;- 4

# generate data and calculate "y"
set.seed(1)
y &lt;- a*sin(b*x)+error*amp 
```

---


```r
library(tidyverse)

sin_df &lt;- tibble(x = x, y = y, truth = a*sin(b*x))
ggplot(sin_df, aes(x, y)) +
  geom_point() +
  geom_line(aes(y = truth))
```

![](w7p1-decision-trees_files/figure-html/plot-sin-1.png)&lt;!-- --&gt;


---
# Fit a simple model - one split


```r
library(rpart)
library(rpart.plot)

mean(sin_df$y)
```

```
## [1] -0.01301011
```

```r
stump &lt;- rpart(y ~ x, 
               data = sin_df,
*              control = list(maxdepth = 1)) # limit tree depth
```

---

```r
summary(stump)
```

```
## Call:
## rpart(formula = y ~ x, data = sin_df, control = list(maxdepth = 1))
##   n= 200 
## 
##          CP nsplit rel error    xerror       xstd
## 1 0.3047571      0 1.0000000 1.0074022 0.08960790
## 2 0.0100000      1 0.6952429 0.7230072 0.06976127
## 
## Variable importance
##   x 
## 100 
## 
## Node number 1: 200 observations,    complexity param=0.3047571
##   mean=-0.01301011, MSE=30.4988 
##   left son=2 (116 obs) right son=3 (84 obs)
##   Primary splits:
##       x &lt; 1.468593 to the right, improve=0.3047571, (0 missing)
## 
## Node number 2: 116 observations
##   mean=-2.607362, MSE=24.58796 
## 
## Node number 3: 84 observations
##   mean=3.569667, MSE=16.53109
```

---
# View the tree


```r
rpart.plot(stump)
```

![](w7p1-decision-trees_files/figure-html/view-stump-1.png)&lt;!-- --&gt;

---
# Visualize the split


```r
sin_df %&gt;%
  mutate(pred = predict(stump)) %&gt;%
ggplot(aes(x, y)) +
  geom_point() +
  geom_line(aes(y = truth)) +
  geom_line(aes(y = pred), color = "red")
```

![](w7p1-decision-trees_files/figure-html/one-splt-1.png)&lt;!-- --&gt;

---
# More complicated
* Note that we only have one predictor - but we can use that predictor multiple times

* Let's specify it again with two splits


```r
twosplit &lt;- rpart(y ~ x, 
                  data = sin_df,
                  control = list(maxdepth = 2))
```

---
# View tree

```r
rpart.plot(twosplit)
```

![](w7p1-decision-trees_files/figure-html/twosplit-tree-1.png)&lt;!-- --&gt;

---
# Visualize two splits


```r
sin_df %&gt;%
  mutate(pred = predict(twosplit)) %&gt;%
ggplot(aes(x, y)) +
  geom_point() +
  geom_line(aes(y = truth)) +
  geom_line(aes(y = pred), color = "red")
```

![](w7p1-decision-trees_files/figure-html/two-splt-1.png)&lt;!-- --&gt;

---
# More complicated
Let's try with 10 splits


```r
tensplit &lt;- rpart(y ~ x, 
                  data = sin_df,
                  control = list(minsplit = 0,
                                 cp = 0,
                                 maxdepth = 10))
```

Notice I've changed the complexity parameter, `cp`, to be 0, which will force it to grow a full tree (more on this in a bit)

---

```r
rpart.plot(tensplit)
```

![](w7p1-decision-trees_files/figure-html/tensplit-tree-1.png)&lt;!-- --&gt;

---


```r
sin_df %&gt;%
  mutate(pred = predict(tensplit)) %&gt;%
ggplot(aes(x, y)) +
  geom_point() +
  geom_line(aes(y = truth)) +
  geom_line(aes(y = pred), color = "red")
```

![](w7p1-decision-trees_files/figure-html/ten-splt-1.png)&lt;!-- --&gt;

---
# Tree depth
* The above probably leaves you thinking... how deep should I grow the trees?
  + Super deep - likely to overfit (high variance)
  + Super shallow - likely to underfit (high bias)



--
### Two primary approaches

* Stop the tree early
* Grow the tree deep, then prune it back


---
# Stopping early
Two primary approaches: 

* Limit the depth
* Limit the *n* size within a terminal node

---
background-image: url(https://bradleyboehmke.github.io/HOML/07-decision-trees_files/figure-html/dt-early-stopping-1.png)
background-size:cover

---
# Pruning
* Tree is grown to a great depth, increasing the likelihood that important interactions in the data are captured.
* The large tree is "pruned" to a smaller subtree that captures (ideally) only the meaningful variation in the data.



--
### Cost complexity
* Typically denoted `\(\alpha\)`, the cost complexity introduces a penalization to the SSE (discussed earlier).

$$
SSE + \alpha\mid{T}\mid
$$

where `\(T\)` is the number of terminal nodes/leafs

---
# Cost complexity

* The equation on the previous slide is .red[minimized] and, for a given `\(\alpha\)`, we identify (from the large tree) a subtree with the lowest penalized error.

* There is a clear association between this penalization and lasso regression.

* `\(\alpha\)` is typically determined via grid search with cross-validation
  - smaller penalties = more complex trees
  - larger penalties = smaller trees

* When pruning a tree, the reduction in the SSE must be larger than the cost complexity penalty.

---
## What about for classification problems?
The basic structure is the same - split the predictor space into regions, make predictions based on the most prominent class


```r
class &lt;- rpart(Species ~ Sepal.Length + Sepal.Width, 
               data = iris,
               method = "class")
```

Notice I've added `method = class` to specify it as a classification problem. If `y` is a factor it will do this automatically, but good to be specific.

---

```r
rpart.plot(class)
```

![](w7p1-decision-trees_files/figure-html/class-tree-1.png)&lt;!-- --&gt;

---
![](w7p1-decision-trees_files/figure-html/iris-regions-1.png)&lt;!-- --&gt;

---
# An applied example
* Let's look at the Kaggle data science bowl data again


```r
train &lt;- read_csv(
    here::here("data", "data-science-bowl-2019", "train.csv"),
    n_max = 7e4 # Limit cases for speed of producing these slides
  ) %&gt;%
  select(-event_data)

train_labels &lt;- read_csv(
  here::here("data", "data-science-bowl-2019", "train_labels.csv")
)
```


---
# Inspect the keys


```r
train_labels %&gt;%
  count(game_session, installation_id) %&gt;%
  filter(n &gt; 1)
```

```
## # A tibble: 0 x 3
## # â€¦ with 3 variables: game_session &lt;chr&gt;, installation_id &lt;chr&gt;, n &lt;int&gt;
```

```r
train %&gt;%
  count(game_session, installation_id) %&gt;%
  filter(n &gt; 1)
```

```
## # A tibble: 710 x 3
##    game_session     installation_id     n
##    &lt;chr&gt;            &lt;chr&gt;           &lt;int&gt;
##  1 0132ad94d2c5e234 00e17272           90
##  2 01a1a7d058854c47 00a803f0           19
##  3 01d44d1b32c3da7f 00691033           56
##  4 021462bb2394e97b 00691033          126
##  5 02546c6aa91244cd 00cef781           90
##  6 025afc11b92cfe4c 00fc65b6           62
##  7 02d9c0f8b9d25cf8 00fa8681           24
##  8 031f9b0a80aa39aa 00e536bf           83
##  9 032880a4dca1fb6b 015776b4           14
## 10 0334295374a6db00 00d8a6f2          125
## # â€¦ with 700 more rows
```

---
# Join the data


```r
k_train &lt;- left_join(train, train_labels)

# check join is as expected
nrow(train); nrow(k_train)
```

```
## [1] 70000
```

```
## [1] 70000
```

---
# Select only vars in test data


```r
model_set &lt;- k_train %&gt;%
  select(event_count, event_code, game_time, title, world, 
         accuracy_group) %&gt;%
  drop_na(accuracy_group)
model_set
```

```
## # A tibble: 4,840 x 6
##    event_count event_code game_time title                world    accuracy_group
##          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;             &lt;dbl&gt;
##  1           1       2000         0 Mushroom Sorter (Asâ€¦ TREETOPâ€¦              3
##  2           2       2025        37 Mushroom Sorter (Asâ€¦ TREETOPâ€¦              3
##  3           3       3010        37 Mushroom Sorter (Asâ€¦ TREETOPâ€¦              3
##  4           4       3110      3901 Mushroom Sorter (Asâ€¦ TREETOPâ€¦              3
##  5           5       3010      3901 Mushroom Sorter (Asâ€¦ TREETOPâ€¦              3
##  6           6       4025      6475 Mushroom Sorter (Asâ€¦ TREETOPâ€¦              3
##  7           7       3110      6475 Mushroom Sorter (Asâ€¦ TREETOPâ€¦              3
##  8           8       3021      6475 Mushroom Sorter (Asâ€¦ TREETOPâ€¦              3
##  9           9       3121      7084 Mushroom Sorter (Asâ€¦ TREETOPâ€¦              3
## 10          10       4025      8400 Mushroom Sorter (Asâ€¦ TREETOPâ€¦              3
## # â€¦ with 4,830 more rows
```

---
# Fit preliminary model


```r
kag_m1 &lt;- rpart(accuracy_group ~ ., 
                data = model_set,
                method = "class")
```

---
# View tree


```r
rpart.plot(kag_m1)
```

![](w7p1-decision-trees_files/figure-html/kagg-prelim-tree-1.png)&lt;!-- --&gt;

---
# Why this tree?
* `rpart` automatically performs 10-fold CV to a range of `\(\alpha\)` values

* In this example, we don't get much information after 4 splits


---
# View the CV cost complexity
* Y - axis is the CV error
* bottom x-axis is `\(\alpha\)`, top is number of terminal nodes
* horizontal line is 1 SE above minimum


```r
plotcp(kag_m1)
```

![](w7p1-decision-trees_files/figure-html/cost-complexity-cv1-1.png)&lt;!-- --&gt;

---
# Change what's on top


```r
plotcp(kag_m1, upper = "splits")
```

![](w7p1-decision-trees_files/figure-html/cost-complexity-cv2-1.png)&lt;!-- --&gt;

---
# Set cost complexity to zero


```r
kag_m2 &lt;- rpart(accuracy_group ~ ., 
                data = model_set,
                method = "class",
                control = list(cp = 0))
plotcp(kag_m2)
abline(v = 5, col = "cornflowerblue", lwd = 2)
```

![](w7p1-decision-trees_files/figure-html/cost-complexity-cv3-1.png)&lt;!-- --&gt;

---
# Get CV results


```r
kag_m1$cptable
```

```
##           CP nsplit rel error    xerror       xstd
## 1 0.26510183      0 1.0000000 1.0000000 0.01177171
## 2 0.06351398      1 0.7348982 0.7348982 0.01192014
## 3 0.01863997      2 0.6713842 0.6713842 0.01177370
## 4 0.01035554      5 0.6057991 0.6071798 0.01155068
## 5 0.01000000      6 0.5954436 0.6020021 0.01152929
```

---
# ðŸ¤¨

I'll be honest, the errors on the previous slide confuse me a bit in this case because they are clearly not Gini index values.


--
In a regression problem, the rel error is 1 - `\(R^2\)`. But what does it represent in classification problems? 


--
# ðŸ¤·
I looked a lot and couldn't find it. Let me know if you find out.


--
`xerror` is the 10-fold cross validation error. This is what you should select to prune your tree (if you want to prune it beyond the default)


--
`xstd` is the standard deviation of the error rate from the cross-validation


---
## What I do know about these values
* `rel error` can be multiplied by the root node error to obtain the *resubstitution* error rate - i.e., 1 - the classification accuracy for the model when evaluated against the data it was trained on.

---

```r
printcp(kag_m1)
```

```
## 
## Classification tree:
## rpart(formula = accuracy_group ~ ., data = model_set, method = "class")
## 
## Variables actually used in tree construction:
## [1] event_count game_time   title      
## 
## Root node error: 2897/4840 = 0.59855
## 
## n= 4840 
## 
##         CP nsplit rel error  xerror     xstd
## 1 0.265102      0   1.00000 1.00000 0.011772
## 2 0.063514      1   0.73490 0.73490 0.011920
## 3 0.018640      2   0.67138 0.67138 0.011774
## 4 0.010356      5   0.60580 0.60718 0.011551
## 5 0.010000      6   0.59544 0.60200 0.011529
```

---
* Our best `rel error` value was `0.59544` with a root node error of `0.5985`.


--
The resubstitution error is therefore: `\(0.59544 * 0.5985 = 0.3563708\)`


---
# Confirm
### First look at the table


```r
class_pred &lt;- table("Model Prediction" = predict(kag_m1, type = "class"), 
                    "Observed" = model_set$accuracy_group)
class_pred
```

```
##                 Observed
## Model Prediction    0    1    2    3
##                0 1603  408  262  279
##                1   25  107   23    0
##                2    0    0  108    0
##                3  315  147  266 1297
```

```r
correct_predictions &lt;- sum(diag(class_pred))
n_cases &lt;- sum(class_pred)
1 - (correct_predictions/n_cases)
```

```
## [1] 0.356405
```

---
# Same thing with `xerror`
The results on the previous slide are overly optimistic. What do we get with the cross-validated error?


--
`\(0.60200 * 0.5985 = 0.360297\)`


--
In this case, just slightly higher error rate.


---
# Prune the tree
There may be cases when you want to manually prune the tree becuase you think it's overfit. We could go back to our full tree but that will result in a really deep tree in this case that definitely overfits (I tried)


--
Let's say we wanted the tree that with an `xerror` 1 SE below the minimum


```r
kag_m1$cptable
```

```
##           CP nsplit rel error    xerror       xstd
## 1 0.26510183      0 1.0000000 1.0000000 0.01177171
## 2 0.06351398      1 0.7348982 0.7348982 0.01192014
## 3 0.01863997      2 0.6713842 0.6713842 0.01177370
## 4 0.01035554      5 0.6057991 0.6071798 0.01155068
## 5 0.01000000      6 0.5954436 0.6020021 0.01152929
```

---
# Filter for min `xerror`


```r
kag_m1$cptable %&gt;% 
  as.data.frame() %&gt;%  # cptable is a matrix...
  filter(xerror == min(xerror))
```

```
##     CP nsplit rel error    xerror       xstd
## 1 0.01      6 0.5954436 0.6020021 0.01152929
```


---
# Find CP values &gt;= 1 SE


```r
kag_m1$cptable %&gt;% 
  as.data.frame() %&gt;%  # cptable is a matrix...
  filter(xerror &gt;= 0.6020021 + 0.01152929)
```

```
##           CP nsplit rel error    xerror       xstd
## 1 0.26510183      0 1.0000000 1.0000000 0.01177171
## 2 0.06351398      1 0.7348982 0.7348982 0.01192014
## 3 0.01863997      2 0.6713842 0.6713842 0.01177370
```

---
# Pull CP from min of these


```r
best_cp &lt;- kag_m1$cptable %&gt;% 
  as.data.frame() %&gt;%  # cptable is a matrix...
  filter(xerror &gt;= 0.6020021 + 0.01152929) %&gt;% 
  filter(xerror == min(xerror)) %&gt;% 
  pull(CP)
best_cp
```

```
## [1] 0.01863997
```


---
# Prune tree

```r
pruned &lt;- prune(kag_m1, cp = best_cp)
rpart.plot(pruned)
```

![](w7p1-decision-trees_files/figure-html/prune-tree-1.png)&lt;!-- --&gt;

---
# Want other metrics?
* I think these error rates are sort of difficult to interpret in classification problems.

* Use {caret} to get other metrics.


```r
# minor data prep
model_set2 &lt;- model_set %&gt;% 
  mutate(
    accuracy_group = factor(paste("score", accuracy_group, sep = "_"))
  )
model_set2
```

```
## # A tibble: 4,840 x 6
##    event_count event_code game_time title                world    accuracy_group
##          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;    &lt;fct&gt;         
##  1           1       2000         0 Mushroom Sorter (Asâ€¦ TREETOPâ€¦ score_3       
##  2           2       2025        37 Mushroom Sorter (Asâ€¦ TREETOPâ€¦ score_3       
##  3           3       3010        37 Mushroom Sorter (Asâ€¦ TREETOPâ€¦ score_3       
##  4           4       3110      3901 Mushroom Sorter (Asâ€¦ TREETOPâ€¦ score_3       
##  5           5       3010      3901 Mushroom Sorter (Asâ€¦ TREETOPâ€¦ score_3       
##  6           6       4025      6475 Mushroom Sorter (Asâ€¦ TREETOPâ€¦ score_3       
##  7           7       3110      6475 Mushroom Sorter (Asâ€¦ TREETOPâ€¦ score_3       
##  8           8       3021      6475 Mushroom Sorter (Asâ€¦ TREETOPâ€¦ score_3       
##  9           9       3121      7084 Mushroom Sorter (Asâ€¦ TREETOPâ€¦ score_3       
## 10          10       4025      8400 Mushroom Sorter (Asâ€¦ TREETOPâ€¦ score_3       
## # â€¦ with 4,830 more rows
```


---
# Train model


```r
library(caret)
train_cv &lt;- train(
  accuracy_group ~ .,
  data = model_set2,
  method = "rpart",
  metric = "AUC",
  trControl = trainControl(method = "cv", 
                           number = 10, 
                           summaryFunction = multiClassSummary,
                           classProbs = TRUE),
  tuneLength = 20
)
```

---
# Plot

```r
plot(train_cv) 
```

![](w7p1-decision-trees_files/figure-html/caret-plot-1.png)&lt;!-- --&gt;

---
# Other metrics

```r
train_cv$results %&gt;% 
  as_tibble()
```

```
## # A tibble: 20 x 29
##             cp   logLoss       AUC      prAUC  Accuracy     Kappa     Mean_F1
##          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
##  1 9.492579e-4 1.199806  0.8113878 0.5281000  0.6642507 0.4899473   0.5566837
##  2 1.035554e-3 1.187014  0.8088018 0.5283020  0.6628044 0.4868868   0.5541979
##  3 1.208146e-3 1.146277  0.8075946 0.5308334  0.6580557 0.4794332   0.5484414
##  4 1.265677e-3 1.139444  0.8074609 0.5312231  0.6582627 0.4799082   0.5485522
##  5 1.380739e-3 1.107649  0.8066108 0.5315874  0.6566085 0.4770238   0.5443662
##  6 1.467035e-3 1.095441  0.8062490 0.5326451  0.6566086 0.4769395   0.5440896
##  7 1.725923e-3 1.045480  0.8010846 0.5296572  0.6524729 0.4691509   0.5354461
##  8 1.898516e-3 1.039051  0.7979768 0.5249138  0.6495914 0.4632623   0.5289101
##  9 1.933034e-3 1.031150  0.7957537 0.5248439  0.6473195 0.4589865   0.5251524
## 10 2.071108e-3 1.036909  0.7898100 0.5194948  0.6450434 0.4548045   0.5190428
## 11 2.761477e-3 1.016793  0.7770467 0.4876336  0.6405009 0.4451581   0.5008640
## 12 2.934070e-3 1.019242  0.7751514 0.4826956  0.6402942 0.4441805   0.4985124
## 13 4.372339e-3 1.008576  0.7673829 0.4129341  0.6361671 0.4369221   0.4879145
## 14 4.832585e-3 0.9951858 0.7647641 0.3745414  0.6334769 0.4315624   0.4831645
## 15 8.284432e-3 0.9958822 0.7610581 0.3565139  0.6299649 0.4243046   0.4689254
## 16 1.173628e-2 1.023580  0.7443481 0.2849539  0.6138406 0.3926521   0.4934593
## 17 2.899551e-2 1.056523  0.7244694 0.2423132  0.5962781 0.3583148 NaN        
## 18 3.814291e-2 1.088222  0.6986704 0.2020808  0.5747822 0.3265536 NaN        
## 19 1.180532e-1 1.177781  0.6213493 0.1201521  0.4989593 0.2299120 NaN        
## 20 1.242665e-1 1.229715  0.5576780 0.05918645 0.4423359 0.1160296 NaN        
## # â€¦ with 22 more variables: Mean_Sensitivity &lt;dbl&gt;, Mean_Specificity &lt;dbl&gt;,
## #   Mean_Pos_Pred_Value &lt;dbl&gt;, Mean_Neg_Pred_Value &lt;dbl&gt;, Mean_Precision &lt;dbl&gt;,
## #   Mean_Recall &lt;dbl&gt;, Mean_Detection_Rate &lt;dbl&gt;, Mean_Balanced_Accuracy &lt;dbl&gt;,
## #   logLossSD &lt;dbl&gt;, AUCSD &lt;dbl&gt;, prAUCSD &lt;dbl&gt;, AccuracySD &lt;dbl&gt;,
## #   KappaSD &lt;dbl&gt;, Mean_F1SD &lt;dbl&gt;, Mean_SensitivitySD &lt;dbl&gt;,
## #   Mean_SpecificitySD &lt;dbl&gt;, Mean_Pos_Pred_ValueSD &lt;dbl&gt;,
## #   Mean_Neg_Pred_ValueSD &lt;dbl&gt;, Mean_PrecisionSD &lt;dbl&gt;, Mean_RecallSD &lt;dbl&gt;,
## #   Mean_Detection_RateSD &lt;dbl&gt;, Mean_Balanced_AccuracySD &lt;dbl&gt;
```

---
# Plot accuracy


```r
ggplot(train_cv$results, aes(cp, Accuracy)) +
  geom_line() +
  geom_point()
```

![](w7p1-decision-trees_files/figure-html/plot-accuracy-1.png)&lt;!-- --&gt;

---
# Feature interpretation
### Which is the most important feature?


```r
library(vip)
vip(train_cv)
```

![](w7p1-decision-trees_files/figure-html/vip1-1.png)&lt;!-- --&gt;

---
# Partial dependency plots

```r
library(pdp)
partial(train_cv, pred.var = "game_time") %&gt;% 
  autoplot()
```

![](w7p1-decision-trees_files/figure-html/pdps1-1.png)&lt;!-- --&gt;

---
# Event count

```r
partial(train_cv, pred.var = "event_count") %&gt;% 
  autoplot()
```

![](w7p1-decision-trees_files/figure-html/pdps2-1.png)&lt;!-- --&gt;

---
# Game time and event count


```r
partial(train_cv, pred.var = c("game_time", "event_count")) %&gt;% 
  autoplot()
```

![](w7p1-decision-trees_files/figure-html/pdps3-1.png)&lt;!-- --&gt;

---
# Alternative representation


```r
partial(train_cv, pred.var = c("game_time", "event_count")) %&gt;% 
  plotPartial(levelplot = FALSE)
```

![](w7p1-decision-trees_files/figure-html/pdps4-1.png)&lt;!-- --&gt;

---
# Conclusions
* Decision trees have a lot of benefits
  - Non-parametric 
  - Easily interpretable (follow a branch)
  - Can produce highly non-linear models


--
* They also have a lot of drawbacks
  - Generally not the most predictive out-of-sample
  - Can produce highly non-linear models


--
* We'll have a lab on decision trees next class, then extend this discussion to models that build ensembles of trees starting next week.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "atelier-dune-light",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
