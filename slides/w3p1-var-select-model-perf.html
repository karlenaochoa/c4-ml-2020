<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Variable selection and model performance</title>
    <meta charset="utf-8" />
    <meta name="author" content="Daniel Anderson" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uo.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uo-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/hygge.css" rel="stylesheet" />
    <link href="libs/countdown-0.3.5/countdown.css" rel="stylesheet" />
    <script src="libs/countdown-0.3.5/countdown.js"></script>
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Variable selection and model performance
## A walkthrough
### Daniel Anderson
### Week 3, Class 1

---




# Agenda

* Create a stratified split dataset

* Specify a linear regression model

* Use `\(k\)`-fold evaluation to evaluate different model fits 

* Compare models based on evaluation criteria

* Visualize and inspect measures of variable importance to refine model

* Evaluate on test set

---
# Scenario
* Imagine you have a dataset with a lot of variables

* You don't know much about what relates to the outcomes


--
* .bolder[.b[GOAL]]: Figure out the most important subset of variables that relate to the outcome


---
# Workflow
* Split the dataset into train/test sets


--
* Prepare the dataset for `\(k\)`-fold cross validation


--
* Determine the type of model you will fit, and the problem type (regression or classification)


--
* Compare different models against the chosen objective funtion through `\(k\)`-fold CV


--
* Settle on a final model, and evaluate it against the test dataset


---
# Load the data
* Please follow along!


```r
library(tidyverse)
library(tidymodels)
d &lt;- read_csv(here::here("data", "edld-654-spring-2020", "train.csv"))
head(d)
```

```
## # A tibble: 6 x 40
##      id gndr  ethnic_cd attnd_dist_inst_id attnd_schl_inst_id enrl_grd
##   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                  &lt;dbl&gt;              &lt;dbl&gt;    &lt;dbl&gt;
## 1     1 F     H                       2142               1330        6
## 2     2 M     W                       2138                785        5
## 3     3 M     M                       1995               3400        8
## 4     5 F     H                       2053               1773        8
## 5     7 F     H                       1964                191        8
## 6    10 M     H                       1948                184        8
## # â€¦ with 34 more variables: calc_admn_cd &lt;lgl&gt;, tst_bnch &lt;chr&gt;, tst_dt &lt;chr&gt;,
## #   migrant_ed_fg &lt;chr&gt;, ind_ed_fg &lt;chr&gt;, sp_ed_fg &lt;chr&gt;, tag_ed_fg &lt;chr&gt;,
## #   econ_dsvntg &lt;chr&gt;, ayp_lep &lt;chr&gt;, stay_in_dist &lt;chr&gt;, stay_in_schl &lt;chr&gt;,
## #   dist_sped &lt;chr&gt;, trgt_assist_fg &lt;chr&gt;, ayp_dist_partic &lt;chr&gt;,
## #   ayp_schl_partic &lt;chr&gt;, ayp_dist_prfrm &lt;chr&gt;, ayp_schl_prfrm &lt;chr&gt;,
## #   rc_dist_partic &lt;chr&gt;, rc_schl_partic &lt;chr&gt;, rc_dist_prfrm &lt;chr&gt;,
## #   rc_schl_prfrm &lt;chr&gt;, partic_dist_inst_id &lt;dbl&gt;, partic_schl_inst_id &lt;dbl&gt;,
## #   lang_cd &lt;chr&gt;, tst_atmpt_fg &lt;chr&gt;, grp_rpt_dist_partic &lt;chr&gt;,
## #   grp_rpt_schl_partic &lt;chr&gt;, grp_rpt_dist_prfrm &lt;chr&gt;,
## #   grp_rpt_schl_prfrm &lt;chr&gt;, score &lt;dbl&gt;, classification &lt;dbl&gt;, ncessch &lt;dbl&gt;,
## #   lat &lt;dbl&gt;, lon &lt;dbl&gt;
```

---
class: inverse center middle
# House cleaning

---
# Initial cleanup
* Remove classification column
* Recode missing data on a few variables


```r
d &lt;- d %&gt;% 
  select(-classification)  %&gt;% 
  mutate(lang_cd = ifelse(is.na(lang_cd), "E", lang_cd),
         calc_admn_cd = ifelse(is.na(calc_admn_cd), "G", calc_admn_cd),
         ayp_lep = ifelse(is.na(ayp_lep), "G", ayp_lep),
         tst_dt = lubridate::as_date(lubridate::mdy_hms(tst_dt)))
```

* Let's also make things really easy on ourselves, and remove all missing data.


```r
d &lt;- d %&gt;% 
  mutate_if(is.character, as.factor) %&gt;% 
  drop_na()
```

---
# Check out the data


```r
d %&gt;% 
  mutate_if(is.character, as.factor) %&gt;% 
  map(summary)
```

```
## $id
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##       1   62947  125720  125940  188946  252565 
## 
## $gndr
##     F     M 
## 90677 94925 
## 
## $ethnic_cd
##      A      B      H      I      M      P      W 
##   7507   4051  45489   2406  11589   1407 113153 
## 
## $attnd_dist_inst_id
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    1894    2039    2142    2120    2188    4131 
## 
## $attnd_schl_inst_id
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##       1     481     932    1351    1288    5382 
## 
## $enrl_grd
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   3.000   4.000   5.000   5.466   7.000   8.000 
## 
## $calc_admn_cd
##      G 
## 185602 
## 
## $tst_bnch
##    1B    2B    3B    G4    G6    G7 
## 30774 32003 29681 32041 31109 29994 
## 
## $tst_dt
##         Min.      1st Qu.       Median         Mean      3rd Qu.         Max. 
## "2018-02-06" "2018-05-11" "2018-05-18" "2018-05-17" "2018-05-24" "2018-06-08" 
## 
## $migrant_ed_fg
##      N      Y 
## 180419   5183 
## 
## $ind_ed_fg
##      N      y      Y 
## 183453      5   2144 
## 
## $sp_ed_fg
##      N      Y 
## 160726  24876 
## 
## $tag_ed_fg
##      N      Y 
## 175077  10525 
## 
## $econ_dsvntg
##      N      Y 
##  77431 108171 
## 
## $ayp_lep
##      A      B      E      F      G      M      N      S      W      X      Y 
##     99    754   6244  15554 147793    162   3761     92    223   3046   7874 
## 
## $stay_in_dist
##      N      Y 
##   4492 181110 
## 
## $stay_in_schl
##      N      Y 
##   5640 179962 
## 
## $dist_sped
##      N      Y 
## 184450   1152 
## 
## $trgt_assist_fg
##      N      y      Y 
## 177626     61   7915 
## 
## $ayp_dist_partic
##      N      Y 
##      0 185602 
## 
## $ayp_schl_partic
##      N      Y 
##   1152 184450 
## 
## $ayp_dist_prfrm
##      N      Y 
##   5108 180494 
## 
## $ayp_schl_prfrm
##      N      Y 
##   7293 178309 
## 
## $rc_dist_partic
##      N      Y 
##      0 185602 
## 
## $rc_schl_partic
##      N      Y 
##   1152 184450 
## 
## $rc_dist_prfrm
##      N      Y 
##   5108 180494 
## 
## $rc_schl_prfrm
##      N      Y 
##   7293 178309 
## 
## $partic_dist_inst_id
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    1894    2039    2142    2120    2190    4131 
## 
## $partic_schl_inst_id
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##       1     482     932    1352    1289    5382 
## 
## $lang_cd
##      E      S 
## 181317   4285 
## 
## $tst_atmpt_fg
##      P      Y 
##    623 184979 
## 
## $grp_rpt_dist_partic
##      N      Y 
##      0 185602 
## 
## $grp_rpt_schl_partic
##      N      Y 
##   1152 184450 
## 
## $grp_rpt_dist_prfrm
##      N      Y 
##    853 184749 
## 
## $grp_rpt_schl_prfrm
##      N      Y 
##   2004 183598 
## 
## $score
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    1601    2421    2498    2499    2576    3550 
## 
## $ncessch
##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
## 4.100e+11 4.103e+11 4.108e+11 4.107e+11 4.111e+11 4.114e+11 
## 
## $lat
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   42.01   44.17   45.25   44.77   45.50   46.18 
## 
## $lon
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  -124.5  -123.0  -122.8  -122.5  -122.5  -116.9
```

---
# Remove constant variables


```r
d &lt;- d %&gt;% 
  select(-grp_rpt_dist_partic, -rc_dist_partic,
         -ayp_dist_partic, -calc_admn_cd)
```

---
class:inverse center middle
# Split the data

---
# Split the data
Note that this is already our "training" data, but we have to treat it like our full data (we don't have labels for the "test" data).

--

* Set a seed


--
* Create an initial split
  + Consider any stratification variables
  + Consdider what proportion you want in test/training


--
* Pull the training data
  + You could pull the test data too, but I usually wait until I get to the evaluation period.

--

```r
set.seed(123)
splt &lt;- initial_split(d, strata = lang_cd)
train &lt;- training(splt)
```

---
# Check our stratification

.pull-left[

```r
d %&gt;% 
  count(lang_cd) %&gt;% 
  mutate(prop = n/sum(n))
```

```
## # A tibble: 2 x 3
##   lang_cd      n       prop
##   &lt;fct&gt;    &lt;int&gt;      &lt;dbl&gt;
## 1 E       181317 0.9769130 
## 2 S         4285 0.02308704
```
]

.pull-right[

```r
train %&gt;% 
  count(lang_cd) %&gt;% 
  mutate(prop = n/sum(n))
```

```
## # A tibble: 2 x 3
##   lang_cd      n       prop
##   &lt;fct&gt;    &lt;int&gt;      &lt;dbl&gt;
## 1 E       135921 0.9764299 
## 2 S         3281 0.02357006
```
]

---
# Create `\(k\)`-folds

* For now, we'll just use the default 10 splits - note this may not *always* work best


--
* High variance betweeen folds? Consider repeated `\(k\)`-fold CV. (not the same thing as increasing number of folds)


--
* How big is your sample? Really large - probably don't need to worry. If small, may need to reduce number of folds


--
* Remember to declare `strata` if needed


--


```r
cv &lt;- vfold_cv(train, strata = lang_cd)
```

---
# Check out the structure
* Remember, just a list column.

```r
cv
```

```
## #  10-fold cross-validation using stratification 
## # A tibble: 10 x 2
##    splits                 id    
##    &lt;named list&gt;           &lt;chr&gt; 
##  1 &lt;split [125.3K/13.9K]&gt; Fold01
##  2 &lt;split [125.3K/13.9K]&gt; Fold02
##  3 &lt;split [125.3K/13.9K]&gt; Fold03
##  4 &lt;split [125.3K/13.9K]&gt; Fold04
##  5 &lt;split [125.3K/13.9K]&gt; Fold05
##  6 &lt;split [125.3K/13.9K]&gt; Fold06
##  7 &lt;split [125.3K/13.9K]&gt; Fold07
##  8 &lt;split [125.3K/13.9K]&gt; Fold08
##  9 &lt;split [125.3K/13.9K]&gt; Fold09
## 10 &lt;split [125.3K/13.9K]&gt; Fold10
```

---
# Looking into it more
* Use `analysis` to extract the data from the corresponding left out fold, or `assessment` to extract all the data *except* the left out fold 


--

.pull-left[


```r
cv$splits[[1]] %&gt;% 
* assessment() %&gt;%
  nrow()
```

```
## [1] 13921
```

```r
13921 / (13921 + 125281)
```

```
## [1] 0.1000057
```

]

.pull-right[


```r
cv$splits[[1]] %&gt;% 
* analysis() %&gt;%
  nrow()
```

```
## [1] 125281
```

```r
125281 / (13921 + 125281)
```

```
## [1] 0.8999943
```

]


---
# Double check our stratification


```r
cv %&gt;% 
  mutate(assessment_props = map(
    splits, ~
      assessment(.x) %&gt;% 
      count(lang_cd) %&gt;% 
      mutate(prop = n/sum(n))
      )
    ) %&gt;% 
  unnest(assessment_props)
```

```
## # A tibble: 20 x 5
##    splits                 id     lang_cd     n       prop
##    &lt;named list&gt;           &lt;chr&gt;  &lt;fct&gt;   &lt;int&gt;      &lt;dbl&gt;
##  1 &lt;split [125.3K/13.9K]&gt; Fold01 E       13598 0.9767976 
##  2 &lt;split [125.3K/13.9K]&gt; Fold01 S         323 0.02320236
##  3 &lt;split [125.3K/13.9K]&gt; Fold02 E       13586 0.9759356 
##  4 &lt;split [125.3K/13.9K]&gt; Fold02 S         335 0.02406436
##  5 &lt;split [125.3K/13.9K]&gt; Fold03 E       13595 0.9766523 
##  6 &lt;split [125.3K/13.9K]&gt; Fold03 S         325 0.02334770
##  7 &lt;split [125.3K/13.9K]&gt; Fold04 E       13588 0.9761494 
##  8 &lt;split [125.3K/13.9K]&gt; Fold04 S         332 0.02385057
##  9 &lt;split [125.3K/13.9K]&gt; Fold05 E       13622 0.9785920 
## 10 &lt;split [125.3K/13.9K]&gt; Fold05 S         298 0.02140805
## 11 &lt;split [125.3K/13.9K]&gt; Fold06 E       13573 0.9750718 
## 12 &lt;split [125.3K/13.9K]&gt; Fold06 S         347 0.02492816
## 13 &lt;split [125.3K/13.9K]&gt; Fold07 E       13597 0.9767960 
## 14 &lt;split [125.3K/13.9K]&gt; Fold07 S         323 0.02320402
## 15 &lt;split [125.3K/13.9K]&gt; Fold08 E       13588 0.9761494 
## 16 &lt;split [125.3K/13.9K]&gt; Fold08 S         332 0.02385057
## 17 &lt;split [125.3K/13.9K]&gt; Fold09 E       13563 0.9743534 
## 18 &lt;split [125.3K/13.9K]&gt; Fold09 S         357 0.02564655
## 19 &lt;split [125.3K/13.9K]&gt; Fold10 E       13611 0.9778017 
## 20 &lt;split [125.3K/13.9K]&gt; Fold10 S         309 0.02219828
```


---
class: inverse center middle
# Specify a model

---
# Select a model
* As we go further in the term, we'll discuss quite a few different modeling options

--

* For now, we'll just use linear regression


```r
mod &lt;- linear_reg()
```

--

* Importantly, we're just setting up the framework here. We're not estimating anything yet.

--


```r
mod
```

```
## Linear Regression Model Specification (regression)
```

---
# Specify an "engine"
* You can estimate a linear regression model a few different ways. For example, you could use OLS or Bayes (via `lm` or `rstanarm::stan_lm` (among others)).

* Again, this will matter more when you get to more adavanced models. Let's just use `lm` as the engine for now.

--


```r
mod &lt;- mod %&gt;% 
  set_engine("lm")
mod
```

```
## Linear Regression Model Specification (regression)
## 
## Computational engine: lm
```

Full options include: `"lm"`, `"glmnet"`, `"stan"`, `"spark"`, and `"keras"`

---
# Specify the mode

* Is this a regression or classification problem?


--
In this case, regression, so


```r
mod &lt;- mod %&gt;% 
  set_mode("regression")
mod
```

```
## Linear Regression Model Specification (regression)
## 
## Computational engine: lm
```

For classification problems, just change `"regression"` to `"classification"`.


--
.b[.bolder[NOTE]]: In this case, we can't estimate a classification problem using linear regression, so it had already set this for us, but it's a good habit to get into anyway.

---
class:inverse center middle
# Fit a model

---
# Fit a model
* Let's start out with fitting a model with gender and special education status, e.g., `score ~ gndr + sp_ed_fg`.


--
* We'll fit this model to the `analysis` portion of every fold, then evaluate it against the `assessment` data in each fold.


--
* We'll do this with the `fit_resamples` function, which takes the following form: `fit_resamples(model, formula, resamples))`


--
* .b[.bolder[NOTE]]: `formula` can also be a `{recipes}` preprocessor object, which we'll talk about later.


--
* There are additional arguments you can pass, but these are the required arguments.

---
# Setting up a recipe
* Before fitting the model, we first have to specify a .ital[.b[recipe]] that tells our engine what model to fit .r[and] and pre-processing steps.


--
* Alternative to `model.matrix`

--
* We will talk about this quite a bit more in two weeks (feature engineering)

* For now, let's just give it the model formula

--


```r
baseline_rec &lt;- recipe(score ~ gndr + sp_ed_fg, train)
```

* Note that I provided the recipe the full training dataset as the data source. The recipe is just using the data source to get the column names.

---
# Inspecting the recipe

```r
baseline_rec
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          2
```

* Similar to specifying the model, nothing is actually happening here - it will be applied to each fold.


--
* Define the role of each column in the dataset (you can define ID variables too)


--
* Specify any pre-processing steps (e.g., center/scale)

---
# Fit to resampled data


```r
m1 &lt;- mod %&gt;% 
  fit_resamples(preprocessor = baseline_rec,
                resamples = cv)
m1
```

```
## #  10-fold cross-validation using stratification 
## # A tibble: 10 x 4
##    splits                 id     .metrics         .notes          
##  * &lt;list&gt;                 &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          
##  1 &lt;split [125.3K/13.9K]&gt; Fold01 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  2 &lt;split [125.3K/13.9K]&gt; Fold02 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  3 &lt;split [125.3K/13.9K]&gt; Fold03 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  4 &lt;split [125.3K/13.9K]&gt; Fold04 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  5 &lt;split [125.3K/13.9K]&gt; Fold05 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  6 &lt;split [125.3K/13.9K]&gt; Fold06 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  7 &lt;split [125.3K/13.9K]&gt; Fold07 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  8 &lt;split [125.3K/13.9K]&gt; Fold08 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  9 &lt;split [125.3K/13.9K]&gt; Fold09 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
## 10 &lt;split [125.3K/13.9K]&gt; Fold10 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
```

---
# Check out evaluation metrics


```r
m1_metrics &lt;- m1 %&gt;% 
  select(id, .metrics) %&gt;% 
  unnest(.metrics) %&gt;% 
  spread(.metric, .estimate)

m1_metrics
```

```
## # A tibble: 10 x 4
##    id     .estimator     rmse        rsq
##    &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;
##  1 Fold01 standard   109.6783 0.09307510
##  2 Fold02 standard   110.2558 0.09416731
##  3 Fold03 standard   109.9944 0.09448588
##  4 Fold04 standard   109.7718 0.09280226
##  5 Fold05 standard   109.4988 0.08682388
##  6 Fold06 standard   111.0818 0.09129834
##  7 Fold07 standard   110.5381 0.08503169
##  8 Fold08 standard   109.7650 0.08914503
##  9 Fold09 standard   110.9788 0.08901039
## 10 Fold10 standard   109.4219 0.09836739
```

.footnote[Note that the model results were not actually saved]

---
# Fit a second model
### Include interaction

* Recipe gets a bit more complicated here. 


```r
interaction_rec &lt;- recipe(score ~ gndr + sp_ed_fg, train) %&gt;% 
  step_dummy(all_predictors()) %&gt;% 
  step_interact(terms = ~ starts_with("gndr"):starts_with("sp_ed_fg"))
interaction_rec
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          2
## 
## Operations:
## 
## Dummy variables from all_predictors
## Interactions with starts_with("gndr"):starts_with("sp_ed_fg")
```

---
# Fit the model


```r
m2 &lt;- mod %&gt;% 
  fit_resamples(interaction_rec, cv)
m2
```

```
## #  10-fold cross-validation using stratification 
## # A tibble: 10 x 4
##    splits                 id     .metrics         .notes          
##  * &lt;list&gt;                 &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          
##  1 &lt;split [125.3K/13.9K]&gt; Fold01 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  2 &lt;split [125.3K/13.9K]&gt; Fold02 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  3 &lt;split [125.3K/13.9K]&gt; Fold03 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  4 &lt;split [125.3K/13.9K]&gt; Fold04 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  5 &lt;split [125.3K/13.9K]&gt; Fold05 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  6 &lt;split [125.3K/13.9K]&gt; Fold06 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  7 &lt;split [125.3K/13.9K]&gt; Fold07 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  8 &lt;split [125.3K/13.9K]&gt; Fold08 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  9 &lt;split [125.3K/13.9K]&gt; Fold09 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
## 10 &lt;split [125.3K/13.9K]&gt; Fold10 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
```


---
# Check evaluation metrics again


```r
m2_metrics &lt;- m2 %&gt;% 
  select(id, .metrics) %&gt;% 
  unnest(.metrics) %&gt;% 
  spread(.metric, .estimate)

m2_metrics
```

```
## # A tibble: 10 x 4
##    id     .estimator     rmse        rsq
##    &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;
##  1 Fold01 standard   109.6598 0.09338219
##  2 Fold02 standard   110.2317 0.09456479
##  3 Fold03 standard   109.9663 0.09494939
##  4 Fold04 standard   109.7731 0.09277420
##  5 Fold05 standard   109.4603 0.08745710
##  6 Fold06 standard   111.0939 0.09110418
##  7 Fold07 standard   110.5445 0.08492744
##  8 Fold08 standard   109.7516 0.08937167
##  9 Fold09 standard   110.9490 0.08949487
## 10 Fold10 standard   109.3987 0.09873319
```


---
# Join metrics


```r
metrics_joined &lt;- left_join(m1_metrics, m2_metrics, 
          by = c("id", ".estimator"),
          suffix = c("_m1", "_m2"))

metrics_joined
```

```
## # A tibble: 10 x 6
##    id     .estimator  rmse_m1     rsq_m1  rmse_m2     rsq_m2
##    &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;
##  1 Fold01 standard   109.6783 0.09307510 109.6598 0.09338219
##  2 Fold02 standard   110.2558 0.09416731 110.2317 0.09456479
##  3 Fold03 standard   109.9944 0.09448588 109.9663 0.09494939
##  4 Fold04 standard   109.7718 0.09280226 109.7731 0.09277420
##  5 Fold05 standard   109.4988 0.08682388 109.4603 0.08745710
##  6 Fold06 standard   111.0818 0.09129834 111.0939 0.09110418
##  7 Fold07 standard   110.5381 0.08503169 110.5445 0.08492744
##  8 Fold08 standard   109.7650 0.08914503 109.7516 0.08937167
##  9 Fold09 standard   110.9788 0.08901039 110.9490 0.08949487
## 10 Fold10 standard   109.4219 0.09836739 109.3987 0.09873319
```

---
# Interaction worth it?
### Move back to long

```r
metrics &lt;- metrics_joined %&gt;% 
  pivot_longer(cols = contains("_"),
               names_to = c("metric", "model"),
               values_to = "estimate",
               names_sep = "_")
metrics
```

```
## # A tibble: 40 x 5
##    id     .estimator metric model     estimate
##    &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;        &lt;dbl&gt;
##  1 Fold01 standard   rmse   m1    109.6783    
##  2 Fold01 standard   rsq    m1      0.09307510
##  3 Fold01 standard   rmse   m2    109.6598    
##  4 Fold01 standard   rsq    m2      0.09338219
##  5 Fold02 standard   rmse   m1    110.2558    
##  6 Fold02 standard   rsq    m1      0.09416731
##  7 Fold02 standard   rmse   m2    110.2317    
##  8 Fold02 standard   rsq    m2      0.09456479
##  9 Fold03 standard   rmse   m1    109.9944    
## 10 Fold03 standard   rsq    m1      0.09448588
## # â€¦ with 30 more rows
```

---
# Inspect by RMSE


```r
metrics %&gt;% 
  filter(metric == "rmse") %&gt;% 
  group_by(id) %&gt;% 
  summarize(estimate = min(estimate)) 
```

```
## # A tibble: 10 x 2
##    id     estimate
##    &lt;chr&gt;     &lt;dbl&gt;
##  1 Fold01 109.6598
##  2 Fold02 110.2317
##  3 Fold03 109.9663
##  4 Fold04 109.7718
##  5 Fold05 109.4603
##  6 Fold06 111.0818
##  7 Fold07 110.5381
##  8 Fold08 109.7516
##  9 Fold09 110.9490
## 10 Fold10 109.3987
```

---


```r
metrics %&gt;% 
  filter(metric == "rmse") %&gt;% 
  group_by(id) %&gt;% 
  summarize(estimate = min(estimate)) %&gt;% 
* semi_join(metrics, .)
```

```
## # A tibble: 10 x 5
##    id     .estimator metric model estimate
##    &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;
##  1 Fold01 standard   rmse   m2    109.6598
##  2 Fold02 standard   rmse   m2    110.2317
##  3 Fold03 standard   rmse   m2    109.9663
##  4 Fold04 standard   rmse   m1    109.7718
##  5 Fold05 standard   rmse   m2    109.4603
##  6 Fold06 standard   rmse   m1    111.0818
##  7 Fold07 standard   rmse   m1    110.5381
##  8 Fold08 standard   rmse   m2    109.7516
##  9 Fold09 standard   rmse   m2    110.9490
## 10 Fold10 standard   rmse   m2    109.3987
```


---

```r
metrics %&gt;% 
  filter(metric == "rmse") %&gt;% 
  group_by(id) %&gt;% 
  summarize(estimate = min(estimate)) %&gt;% 
  semi_join(metrics, .) %&gt;% 
* count(model)
```

```
## # A tibble: 2 x 2
##   model     n
##   &lt;chr&gt; &lt;int&gt;
## 1 m1        3
## 2 m2        7
```


--
### Answer: ðŸ¤·


---
# Alternative way to think about it


```r
metrics_joined %&gt;% 
  mutate(rmse_diff = round(rmse_m1 - rmse_m2, 3),
         rsq_diff  = round(rsq_m1 - rsq_m2, 3)) %&gt;% 
  select(id, ends_with("diff"))
```

```
## # A tibble: 10 x 3
##    id     rmse_diff rsq_diff
##    &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;
##  1 Fold01  0.018000    0    
##  2 Fold02  0.024       0    
##  3 Fold03  0.028       0    
##  4 Fold04 -0.001       0    
##  5 Fold05  0.039      -0.001
##  6 Fold06 -0.012       0    
##  7 Fold07 -0.006       0    
##  8 Fold08  0.013       0    
##  9 Fold09  0.03        0    
## 10 Fold10  0.023       0
```

--
### Conclusion: Probs not

---
# How to improve this model
* I've approached this from a (light) theoretical variable-inclusion perspective

  + Hopefully you have domain knowledge in your application that allows you to start from a meaningful place.
  
  + Other variables that theoretically relate that we could start with (e.g., grade level, economic disadvantage status)
 

--
* What if I didn't know? We could start out by looking at all variables, and choosing the most important


--


```r
library(vip)
vip_1a &lt;- vip(lm(score ~ ., train))
```

---

```r
vip_1a
```

![](w3p1-var-select-model-perf_files/figure-html/show-vip1-1.png)&lt;!-- --&gt;


--

This basically tells us that outside of sped (which we've included already) gifted/talented (tag), economic disadvantage, test date, and ethnic code are important predictors. Let's look a bit deeper.

---

```r
vip_1b &lt;- vi(lm(score ~ ., train))
vip_1b
```

```
## # A tibble: 48 x 3
##    Variable     Importance Sign 
##    &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;
##  1 tag_ed_fgY    117.4957  POS  
##  2 sp_ed_fgY     109.1892  NEG  
##  3 econ_dsvntgY   77.75669 NEG  
##  4 ethnic_cdB     44.59635 NEG  
##  5 ethnic_cdH     39.03411 NEG  
##  6 tst_dt         34.35133 POS  
##  7 ethnic_cdW     26.76342 NEG  
##  8 ethnic_cdM     23.95652 NEG  
##  9 ethnic_cdI     22.80560 NEG  
## 10 ethnic_cdP     21.52754 NEG  
## # â€¦ with 38 more rows
```

Numbers view of the previous plot

---
# Interactions
You can also use vip with interactions


```r
vip_2a &lt;- vip(lm(score ~ .^2, train))
vip_2a
```

![](w3p1-var-select-model-perf_files/figure-html/vip2a-1.png)&lt;!-- --&gt;

---
# New model


```r
post_vip_rec &lt;- recipe(score ~ tag_ed_fg + sp_ed_fg + econ_dsvntg +
                               tst_dt + ethnic_cd, 
                       data = train)

m3 &lt;- mod %&gt;% 
  fit_resamples(post_vip_rec, cv)

m3
```

```
## #  10-fold cross-validation using stratification 
## # A tibble: 10 x 4
##    splits                 id     .metrics         .notes          
##  * &lt;list&gt;                 &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          
##  1 &lt;split [125.3K/13.9K]&gt; Fold01 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  2 &lt;split [125.3K/13.9K]&gt; Fold02 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  3 &lt;split [125.3K/13.9K]&gt; Fold03 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  4 &lt;split [125.3K/13.9K]&gt; Fold04 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  5 &lt;split [125.3K/13.9K]&gt; Fold05 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  6 &lt;split [125.3K/13.9K]&gt; Fold06 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  7 &lt;split [125.3K/13.9K]&gt; Fold07 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  8 &lt;split [125.3K/13.9K]&gt; Fold08 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  9 &lt;split [125.3K/13.9K]&gt; Fold09 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
## 10 &lt;split [125.3K/13.9K]&gt; Fold10 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
```


---
# M3 metrics


```r
m3 %&gt;% 
  select(id, .metrics) %&gt;% 
  unnest(.metrics) %&gt;% 
  spread(.metric, .estimate)
```

```
## # A tibble: 10 x 4
##    id     .estimator     rmse       rsq
##    &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;
##  1 Fold01 standard   97.84657 0.2781628
##  2 Fold02 standard   98.04669 0.2836478
##  3 Fold03 standard   97.56858 0.2875058
##  4 Fold04 standard   97.63753 0.2821901
##  5 Fold05 standard   97.42491 0.2769661
##  6 Fold06 standard   99.17022 0.2756263
##  7 Fold07 standard   97.88499 0.2825361
##  8 Fold08 standard   97.48603 0.2815878
##  9 Fold09 standard   98.06879 0.2888086
## 10 Fold10 standard   97.36285 0.2860995
```

---
## Improving model performance further
* Other variables? (e.g., grade level of general assessment)

* Interactions?
  + `step_interact`

* Nonlinearity?
  + `step_poly`


--
### Refining the model
* We have quite a bit of repeated code here. If this were the strategy we were using, we'd probably want to write functions for the model comparisons.


---
# How are we doing on time?
### Skip if not enough time, otherwise...

Try to refine this model further to boost model performance more! Consider modifications listed in previous slide (inclusion of other variables, nonlinear terms, or interactions)

<div class="countdown" id="timer_5e827554" style="top:0.5;right:0.5;bottom:0.5;left:0.75;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
# Evaluation on test set
* Note we wouldn't usually jump to this point yet, but let's try.


--
### First: Extract test dataset


```r
test &lt;- testing(splt)
test
```

```
## # A tibble: 46,400 x 35
##       id gndr  ethnic_cd attnd_dist_inst_id attnd_schl_inst_id enrl_grd tst_bnch
##    &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;                  &lt;dbl&gt;              &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;   
##  1    24 F     W                       2243               1182        8 3B      
##  2    34 M     H                       1928                115        8 3B      
##  3    43 M     W                       1922               5377        8 3B      
##  4    45 M     H                       1924               3530        7 G7      
##  5    56 F     H                       1970                224        8 3B      
##  6    60 M     H                       1974                235        7 G7      
##  7    64 M     W                       2100               4744        7 G7      
##  8    67 F     W                       2100                638        8 3B      
##  9    71 M     W                       2100                638        7 G7      
## 10    75 F     H                       2100                642        7 G7      
## # â€¦ with 46,390 more rows, and 28 more variables: tst_dt &lt;date&gt;,
## #   migrant_ed_fg &lt;fct&gt;, ind_ed_fg &lt;fct&gt;, sp_ed_fg &lt;fct&gt;, tag_ed_fg &lt;fct&gt;,
## #   econ_dsvntg &lt;fct&gt;, ayp_lep &lt;fct&gt;, stay_in_dist &lt;fct&gt;, stay_in_schl &lt;fct&gt;,
## #   dist_sped &lt;fct&gt;, trgt_assist_fg &lt;fct&gt;, ayp_schl_partic &lt;fct&gt;,
## #   ayp_dist_prfrm &lt;fct&gt;, ayp_schl_prfrm &lt;fct&gt;, rc_schl_partic &lt;fct&gt;,
## #   rc_dist_prfrm &lt;fct&gt;, rc_schl_prfrm &lt;fct&gt;, partic_dist_inst_id &lt;dbl&gt;,
## #   partic_schl_inst_id &lt;dbl&gt;, lang_cd &lt;fct&gt;, tst_atmpt_fg &lt;fct&gt;,
## #   grp_rpt_schl_partic &lt;fct&gt;, grp_rpt_dist_prfrm &lt;fct&gt;,
## #   grp_rpt_schl_prfrm &lt;fct&gt;, score &lt;dbl&gt;, ncessch &lt;dbl&gt;, lat &lt;dbl&gt;, lon &lt;dbl&gt;
```

---
# Fit model


```r
test_mod &lt;- mod %&gt;% 
  fit(score ~ tag_ed_fg + sp_ed_fg + econ_dsvntg +
              tst_dt + ethnic_cd, 
*     data = test)
```

---
# Look at model
### Just for fun


```r
summary(test_mod$fit)
```

```
## 
## Call:
## stats::lm(formula = formula, data = data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -759.83  -64.33   -0.42   64.77  539.33 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -6.657e+03  7.013e+02  -9.493   &lt;2e-16 ***
## tag_ed_fgY    1.317e+02  2.015e+00  65.342   &lt;2e-16 ***
## sp_ed_fgY    -8.725e+01  1.342e+00 -65.029   &lt;2e-16 ***
## econ_dsvntgY -5.300e+01  9.921e-01 -53.421   &lt;2e-16 ***
## tst_dt        5.224e-01  3.969e-02  13.163   &lt;2e-16 ***
## ethnic_cdB   -9.661e+01  3.833e+00 -25.203   &lt;2e-16 ***
## ethnic_cdH   -6.225e+01  2.464e+00 -25.267   &lt;2e-16 ***
## ethnic_cdI   -5.681e+01  4.557e+00 -12.465   &lt;2e-16 ***
## ethnic_cdM   -3.752e+01  2.885e+00 -13.003   &lt;2e-16 ***
## ethnic_cdP   -6.687e+01  5.621e+00 -11.896   &lt;2e-16 ***
## ethnic_cdW   -3.007e+01  2.310e+00 -13.014   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 97.93 on 46389 degrees of freedom
## Multiple R-squared:  0.2846,	Adjusted R-squared:  0.2844 
## F-statistic:  1845 on 10 and 46389 DF,  p-value: &lt; 2.2e-16
```

---
# Make predictions


```r
preds &lt;- test %&gt;% 
  mutate(estimate = predict(test_mod$fit, newdata = .)) %&gt;% 
  select(truth = score, estimate)
preds
```

```
## # A tibble: 46,400 x 2
##    truth estimate
##    &lt;dbl&gt;    &lt;dbl&gt;
##  1  2574 2545.805
##  2  2355 2422.717
##  3  2366 2455.424
##  4  2490 2460.624
##  5  2261 2373.377
##  6  2453 2456.444
##  7  2291 2402.950
##  8  2492 2493.331
##  9  2417 2492.808
## 10  2522 2509.964
## # â€¦ with 46,390 more rows
```

---
# Evaluate prediction


```r
bind_rows(
  rmse(preds, truth, estimate),
  rsq(preds, truth, estimate)
)
```

```
## # A tibble: 2 x 3
##   .metric .estimator  .estimate
##   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;
## 1 rmse    standard   97.91891  
## 2 rsq     standard    0.2845741
```

---
class: inverse center middle

# Evaluation metrics
### Quickly

---
# Big picture
* We've spent most of today talking about the process of building a linear model. But how you determine what is "best" depends (in part) on your evaluation metric.

--

.Large[.center[For regression problems]]

--

.pull-left[
### Well known metrics

* MSE - mean square error
* RMSE - root mean square error
* `\(R^2\)`
]

--

.pull-right[
### Less well-known metrics
* MAE - mean absolute error
* RPIQ - ratio of performance to inter-quartile
* Huber loss - balances MSE and MAE
]

--

see [yardstick documentation](https://tidymodels.github.io/yardstick/reference/index.html) for complete reference of metrics implemented.

---
# A few notes
* RMSE is the mean error, but on the scale of the outcome
  + .b[Pros]: Generally fairly interpretable - how much are your predictions off by, on average?
  + .r[Cons]: The mean (generally) can be suceptible to outliers
  
--
* MAE is the median error
  + .b[Pros]: Less influenced by outliers
  + .r[Cons]: Somewhat less familiar; sometimes the outlier cases are highly important
  
--
* Huber Loss balances (R)MSE and MAE
  + Quadratic for small residual values, linear for large residual values
  + .b[Pros]: Sensitivity of RMSE with robustness of MAE
  + .r[Cons]: Less familiar and interpretable; does not translate to common measure of central tendancy

---
# Huber loss vs squared errors
![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Huber_loss.svg/1920px-Huber_loss.svg.png)

---
# Overall takeaway
* There are more metrics than described above.

--
* Choosing a metric can be really important, and often is driven by the specific problem

.g[.small[Example from handwriting recognition algorithm]]

---
# Kaggle
### Moving back to our model
* What do we need to do to make predictions from this model for kaggle?


--
* Preprocess the `train.csv` using the recipe we used above (particularly if you have interactions)


--
* Fit the model to the preprocessed data


--
* Make predictions
  
  + Will we be able to evaluate?
  

--
* Upload a csv file that has a `Id` and `Predicted` columns. 


---
class: inverse center middle

# Next time
### Lab 2
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "atelier-dune-light",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
