<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Variable selection and model performance</title>
    <meta charset="utf-8" />
    <meta name="author" content="Daniel Anderson" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uo.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uo-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/hygge.css" rel="stylesheet" />
    <link href="libs/countdown-0.3.5/countdown.css" rel="stylesheet" />
    <script src="libs/countdown-0.3.5/countdown.js"></script>
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Variable selection and model performance
## A walkthrough
### Daniel Anderson
### Week 3, Class 1

---




# Agenda

* Create a stratified split dataset

* Specify a linear regression model

* Use `\(k\)`-fold evaluation to evaluate different model fits 

* Compare models based on evaluation criteria

* Visualize and inspect measures of variable importance to refine model

* Evaluate on test set

---
# Scenario
* Imagine you have a dataset with a lot of variables

* You don't know much about what relates to the outcomes


--
* .bolder[.b[GOAL]]: Figure out the most important subset of variables that relate to the outcome


---
# Workflow
* Split the dataset into train/test sets


--
* Prepare the dataset for `\(k\)`-fold cross validation


--
* Determine the type of model you will fit, and the problem type (regression or classification)


--
* Compare different models against the chosen objective funtion through `\(k\)`-fold CV


--
* Settle on a final model, and evaluate it against the test dataset


---
# Load the data
Please follow along!

--
### Dealing with file size
A few people had issues during the last lab because the file is rather large.

Let's use a new package that uses "lazy loading". We can help it further by providing a column specification.

---

```r
library(tidyverse)

col_specs &lt;- cols(
  .default = col_character(),
  id = col_double(),
  attnd_dist_inst_id = col_double(),
  attnd_schl_inst_id = col_double(),
  enrl_grd = col_double(),
  calc_admn_cd = col_logical(),
  partic_dist_inst_id = col_double(),
  partic_schl_inst_id = col_double(),
* lang_cd = col_character(),
  score = col_double(),
  classification = col_double(),
  ncessch = col_double(),
  lat = col_double(),
  lon = col_double()
)
```

---
# How did I get this?
You could do it manually, but that would be a lot of work. Instead, just read in, say, 10 rows, and make any adjustments to the specs you need to after that.


```r
read_csv(here::here("data", "edld-654-spring-2020", "train.csv"),
         n_max = 10)
```

```
## Parsed with column specification:
## cols(
##   .default = col_character(),
##   id = col_double(),
##   attnd_dist_inst_id = col_double(),
##   attnd_schl_inst_id = col_double(),
##   enrl_grd = col_double(),
##   calc_admn_cd = col_logical(),
##   partic_dist_inst_id = col_double(),
##   partic_schl_inst_id = col_double(),
##   lang_cd = col_logical(),
##   score = col_double(),
##   classification = col_double(),
##   ncessch = col_double(),
##   lat = col_double(),
##   lon = col_double()
## )
```

```
## See spec(...) for full column specifications.
```

```
## # A tibble: 10 x 40
##       id gndr  ethnic_cd attnd_dist_inst_id attnd_schl_inst_id enrl_grd
##    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                  &lt;dbl&gt;              &lt;dbl&gt;    &lt;dbl&gt;
##  1     1 F     H                       2142               1330        6
##  2     2 M     W                       2138                785        5
##  3     3 M     M                       1995               3400        8
##  4     5 F     H                       2053               1773        8
##  5     7 F     H                       1964                191        8
##  6    10 M     H                       1948                184        8
##  7    12 F     W                       1924                 84        8
##  8    13 M     W                       1947               4396        8
##  9    14 F     W                       1965                201        8
## 10    16 M     M                       1945                168        8
## # â€¦ with 34 more variables: calc_admn_cd &lt;lgl&gt;, tst_bnch &lt;chr&gt;, tst_dt &lt;chr&gt;,
## #   migrant_ed_fg &lt;chr&gt;, ind_ed_fg &lt;chr&gt;, sp_ed_fg &lt;chr&gt;, tag_ed_fg &lt;chr&gt;,
## #   econ_dsvntg &lt;chr&gt;, ayp_lep &lt;chr&gt;, stay_in_dist &lt;chr&gt;, stay_in_schl &lt;chr&gt;,
## #   dist_sped &lt;chr&gt;, trgt_assist_fg &lt;chr&gt;, ayp_dist_partic &lt;chr&gt;,
## #   ayp_schl_partic &lt;chr&gt;, ayp_dist_prfrm &lt;chr&gt;, ayp_schl_prfrm &lt;chr&gt;,
## #   rc_dist_partic &lt;chr&gt;, rc_schl_partic &lt;chr&gt;, rc_dist_prfrm &lt;chr&gt;,
## #   rc_schl_prfrm &lt;chr&gt;, partic_dist_inst_id &lt;dbl&gt;, partic_schl_inst_id &lt;dbl&gt;,
## #   lang_cd &lt;lgl&gt;, tst_atmpt_fg &lt;chr&gt;, grp_rpt_dist_partic &lt;chr&gt;,
## #   grp_rpt_schl_partic &lt;chr&gt;, grp_rpt_dist_prfrm &lt;chr&gt;,
## #   grp_rpt_schl_prfrm &lt;chr&gt;, score &lt;dbl&gt;, classification &lt;dbl&gt;, ncessch &lt;dbl&gt;,
## #   lat &lt;dbl&gt;, lon &lt;dbl&gt;
```


---

```r
d &lt;- vroom::vroom(
  here::here("data", "edld-654-spring-2020", "train.csv"),
  col_types = col_specs
)
```

---
class: inverse center middle
# House cleaning

---
# Initial cleanup
* Remove classification column
* Recode missing data on a few variables
* Sample only a fraction of the overall data


```r
set.seed(123)
d &lt;- d %&gt;% 
  select(-classification)  %&gt;% 
  mutate(lang_cd = ifelse(is.na(lang_cd), "E", lang_cd),
         ayp_lep = ifelse(is.na(ayp_lep), "G", ayp_lep),
         tst_dt = lubridate::as_date(lubridate::mdy_hms(tst_dt))) %&gt;% 
  # only use a sample
  group_by(lang_cd) %&gt;% 
  sample_frac(.25) %&gt;% # Could even go lower
  ungroup() 
```

---
# Check out the data


```r
d %&gt;% 
  mutate_if(is.character, as.factor) %&gt;% 
  map(summary)
```

```
## $id
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##      18   63177  126290  126332  189310  252557 
## 
## $gndr
##     F     M 
## 23112 24244 
## 
## $ethnic_cd
##     A     B     H     I     M     P     W 
##  1866   964 11344   616  3069   367 29130 
## 
## $attnd_dist_inst_id
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    1894    2041    2142    2120    2190    4131 
## 
## $attnd_schl_inst_id
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##       1     503     938    1380    1303    5392 
## 
## $enrl_grd
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   3.000   4.000   5.000   5.461   7.000   8.000 
## 
## $calc_admn_cd
##    Mode    NA's 
## logical   47356 
## 
## $tst_bnch
##   1B   2B   3B   G4   G6   G7 
## 7847 8172 7597 8281 7902 7557 
## 
## $tst_dt
##         Min.      1st Qu.       Median         Mean      3rd Qu.         Max. 
## "2018-02-06" "2018-05-10" "2018-05-18" "2018-05-17" "2018-05-24" "2018-06-08" 
## 
## $migrant_ed_fg
##     N     Y 
## 46077  1279 
## 
## $ind_ed_fg
##     N     Y  NA's 
## 46802   541    13 
## 
## $sp_ed_fg
##     N     Y  NA's 
## 40936  6407    13 
## 
## $tag_ed_fg
##     N     Y  NA's 
## 44429  2809   118 
## 
## $econ_dsvntg
##     N     Y  NA's 
## 19973 27249   134 
## 
## $ayp_lep
##     A     B     E     F     G     M     N     S     W     X     Y 
##    27   184  1598  3833 37875    43   945    22    69   765  1995 
## 
## $stay_in_dist
##     N     Y  NA's 
##  1193 46045   118 
## 
## $stay_in_schl
##     N     Y  NA's 
##  1499 45739   118 
## 
## $dist_sped
##     N     Y  NA's 
## 46867   371   118 
## 
## $trgt_assist_fg
##     N     y     Y  NA's 
## 45205    16  2015   120 
## 
## $ayp_dist_partic
##     N     Y 
##   134 47222 
## 
## $ayp_schl_partic
##     N     Y 
##   505 46851 
## 
## $ayp_dist_prfrm
##     N     Y 
##  1467 45889 
## 
## $ayp_schl_prfrm
##     N     Y 
##  2103 45253 
## 
## $rc_dist_partic
##     N     Y 
##   134 47222 
## 
## $rc_schl_partic
##     N     Y 
##   505 46851 
## 
## $rc_dist_prfrm
##     N     Y 
##  1467 45889 
## 
## $rc_schl_prfrm
##     N     Y 
##  2103 45253 
## 
## $partic_dist_inst_id
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
##    1894    2041    2142    2120    2190    4131     134 
## 
## $partic_schl_inst_id
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
##       1     503     938    1380    1303    5392     134 
## 
## $lang_cd
##     E     S 
## 46280  1076 
## 
## $tst_atmpt_fg
##     P     Y 
##   142 47214 
## 
## $grp_rpt_dist_partic
##     N     Y 
##   134 47222 
## 
## $grp_rpt_schl_partic
##     N     Y 
##   505 46851 
## 
## $grp_rpt_dist_prfrm
##     N     Y 
##   343 47013 
## 
## $grp_rpt_schl_prfrm
##     N     Y 
##   714 46642 
## 
## $score
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    1662    2422    2498    2499    2576    3091 
## 
## $ncessch
##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.      NA's 
## 4.100e+11 4.103e+11 4.108e+11 4.107e+11 4.111e+11 4.114e+11       775 
## 
## $lat
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
##   42.01   44.20   45.25   44.78   45.50   46.18     819 
## 
## $lon
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
##  -124.5  -123.0  -122.8  -122.5  -122.5  -116.9     819
```

---
# Remove constant variables
* Also make things really easy and remove missing data


```r
d &lt;- d %&gt;% 
  # remove any rows or columns that are fully missing
  janitor::remove_empty(c("rows", "cols")) %&gt;% 
  
  # drop any row that has a missing value
  drop_na() %&gt;% 
  
  # drop any column that doesn't have more than 1 unique value
  select_if(~length(unique(.x)) &gt; 1)
```


---
class:inverse center middle
# Split the data

---
# Split the data
Note that this is already our "training" data, but we have to treat it like our full data (we don't have labels for the "test" data).

--

* Set a seed


--
* Create an initial split
  + Consider any stratification variables
  + Consdider what proportion you want in test/training


--
* Pull the training data
  + You could pull the test data too, but I usually wait until I get to the evaluation period.

--

```r
library(tidymodels)
splt &lt;- initial_split(d, strata = lang_cd)
train &lt;- training(splt)
```

---
# Check our stratification

.pull-left[

```r
d %&gt;% 
  count(lang_cd) %&gt;% 
  mutate(prop = n/sum(n))
```

```
## # A tibble: 2 x 3
##   lang_cd     n       prop
##   &lt;chr&gt;   &lt;int&gt;      &lt;dbl&gt;
## 1 E       45351 0.9769080 
## 2 S        1072 0.02309200
```
]

.pull-right[

```r
train %&gt;% 
  count(lang_cd) %&gt;% 
  mutate(prop = n/sum(n))
```

```
## # A tibble: 2 x 3
##   lang_cd     n       prop
##   &lt;chr&gt;   &lt;int&gt;      &lt;dbl&gt;
## 1 E       34020 0.9770808 
## 2 S         798 0.02291918
```
]

---
# Create `\(k\)`-folds

* For now, we'll just use the default 10 splits - note this may not *always* work best


--
* High variance betweeen folds? Consider repeated `\(k\)`-fold CV. (not the same thing as increasing number of folds)


--
* How big is your sample? Really large - probably don't need to worry. If small, may need to reduce number of folds


--
* Remember to declare `strata` if needed


--


```r
cv &lt;- vfold_cv(train, strata = lang_cd)
```

---
# Check out the structure
* Remember, just a list column.

```r
cv
```

```
## #  10-fold cross-validation using stratification 
## # A tibble: 10 x 2
##    splits               id    
##    &lt;named list&gt;         &lt;chr&gt; 
##  1 &lt;split [31.3K/3.5K]&gt; Fold01
##  2 &lt;split [31.3K/3.5K]&gt; Fold02
##  3 &lt;split [31.3K/3.5K]&gt; Fold03
##  4 &lt;split [31.3K/3.5K]&gt; Fold04
##  5 &lt;split [31.3K/3.5K]&gt; Fold05
##  6 &lt;split [31.3K/3.5K]&gt; Fold06
##  7 &lt;split [31.3K/3.5K]&gt; Fold07
##  8 &lt;split [31.3K/3.5K]&gt; Fold08
##  9 &lt;split [31.3K/3.5K]&gt; Fold09
## 10 &lt;split [31.3K/3.5K]&gt; Fold10
```

---
# Looking into it more
* Use `analysis` to extract the data from the corresponding fold that you will use to estimate the model

* Use `assessment` to extract all .ital[other] data from the corresponding fold, which you will use to evaluate the model 


--

.pull-left[


```r
cv$splits[[1]] %&gt;% 
* assessment() %&gt;%
  nrow()
```

```
## [1] 3482
```

```r
3482 / (3482 + 31336)
```

```
## [1] 0.1000057
```

]

.pull-right[


```r
cv$splits[[1]] %&gt;% 
* analysis() %&gt;%
  nrow()
```

```
## [1] 31336
```

```r
31336 / (3482 + 31336)
```

```
## [1] 0.8999943
```

]


---
# Double check our stratification


```r
cv %&gt;% 
  mutate(assessment_props = map(
    splits, ~
      assessment(.x) %&gt;% 
      count(lang_cd) %&gt;% 
      mutate(prop = n/sum(n))
      )
    ) %&gt;% 
  unnest(assessment_props)
```

```
## # A tibble: 20 x 5
##    splits               id     lang_cd     n       prop
##    &lt;named list&gt;         &lt;chr&gt;  &lt;chr&gt;   &lt;int&gt;      &lt;dbl&gt;
##  1 &lt;split [31.3K/3.5K]&gt; Fold01 E        3402 0.9770247 
##  2 &lt;split [31.3K/3.5K]&gt; Fold01 S          80 0.02297530
##  3 &lt;split [31.3K/3.5K]&gt; Fold02 E        3401 0.9767375 
##  4 &lt;split [31.3K/3.5K]&gt; Fold02 S          81 0.02326249
##  5 &lt;split [31.3K/3.5K]&gt; Fold03 E        3389 0.9732912 
##  6 &lt;split [31.3K/3.5K]&gt; Fold03 S          93 0.02670879
##  7 &lt;split [31.3K/3.5K]&gt; Fold04 E        3408 0.9787478 
##  8 &lt;split [31.3K/3.5K]&gt; Fold04 S          74 0.02125215
##  9 &lt;split [31.3K/3.5K]&gt; Fold05 E        3399 0.9761631 
## 10 &lt;split [31.3K/3.5K]&gt; Fold05 S          83 0.02383688
## 11 &lt;split [31.3K/3.5K]&gt; Fold06 E        3402 0.9770247 
## 12 &lt;split [31.3K/3.5K]&gt; Fold06 S          80 0.02297530
## 13 &lt;split [31.3K/3.5K]&gt; Fold07 E        3407 0.9784607 
## 14 &lt;split [31.3K/3.5K]&gt; Fold07 S          75 0.02153935
## 15 &lt;split [31.3K/3.5K]&gt; Fold08 E        3421 0.9824813 
## 16 &lt;split [31.3K/3.5K]&gt; Fold08 S          61 0.01751867
## 17 &lt;split [31.3K/3.5K]&gt; Fold09 E        3390 0.9738581 
## 18 &lt;split [31.3K/3.5K]&gt; Fold09 S          91 0.02614191
## 19 &lt;split [31.3K/3.5K]&gt; Fold10 E        3401 0.9770181 
## 20 &lt;split [31.3K/3.5K]&gt; Fold10 S          80 0.02298190
```


---
class: inverse center middle
# Specify a model

---
# Select a model
* As we go further in the term, we'll discuss quite a few different modeling options

--

* For now, we'll just use linear regression


```r
mod &lt;- linear_reg()
```

--

* Importantly, we're just setting up the framework here. We're not estimating anything yet.

--


```r
mod
```

```
## Linear Regression Model Specification (regression)
```


--
Let's briefly look at the [full set of models](https://tidymodels.github.io/parsnip/articles/articles/Models.html) that can be estimated within this framework.

---
# Specify an "engine"
* You can estimate a linear regression model a few different ways. For example, you could use OLS or Bayes (via `lm` or `rstanarm::stan_lm` (among others)).

* Again, this will matter more when you get to more adavanced models. Let's just use `lm` as the engine for now.

--


```r
mod &lt;- mod %&gt;% 
  set_engine("lm")
mod
```

```
## Linear Regression Model Specification (regression)
## 
## Computational engine: lm
```

Full options include: `"lm"`, `"glmnet"`, `"stan"`, `"spark"`, and `"keras"`

---
# Specify the mode

* Is this a regression or classification problem?


--
In this case, regression, so


```r
mod &lt;- mod %&gt;% 
  set_mode("regression")
mod
```

```
## Linear Regression Model Specification (regression)
## 
## Computational engine: lm
```

For classification problems, just change `"regression"` to `"classification"`.


--
.b[.bolder[NOTE]]: In this case, we can't estimate a classification problem using linear regression, so it had already set this for us, but it's a good habit to get into anyway.

---
class:inverse center middle
# Fit a model

---
# Fit a model
* Let's start out with fitting a model with gender and special education status, e.g., `score ~ gndr + sp_ed_fg`.


--
* We'll fit this model to the `analysis` portion of every fold, then evaluate it against the `assessment` data in each fold.


--
* We'll do this with the `fit_resamples` function, which takes the following form: `fit_resamples(model, formula, resamples))`


--
* .b[.bolder[NOTE]]: `formula` can also be a `{recipes}` preprocessor object, which we'll talk about later.


--
* There are additional arguments you can pass, but these are the required arguments.

---
# Setting up a recipe
* Before fitting the model, we first have to specify a .ital[.b[recipe]] that tells our engine what model to fit .r[and] and pre-processing steps.


--
* Alternative to `model.matrix`

--
* We will talk about this quite a bit more in two weeks (feature engineering)

* For now, let's just give it the model formula

--


```r
baseline_rec &lt;- recipe(score ~ gndr + sp_ed_fg, train)
```

* Note that I provided the recipe the full training dataset as the data source. The recipe is just using the data source to get the column names.

---
# Inspecting the recipe

```r
baseline_rec
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          2
```

* Similar to specifying the model, nothing is actually happening here - it will be applied to each fold.


--
* Define the role of each column in the dataset (you can define ID variables too)


--
* Specify any pre-processing steps (e.g., center/scale)

---
# Fit to resampled data


```r
m1 &lt;- mod %&gt;% 
  fit_resamples(preprocessor = baseline_rec,
                resamples = cv)
m1
```

```
## #  10-fold cross-validation using stratification 
## # A tibble: 10 x 4
##    splits               id     .metrics         .notes          
##    &lt;list&gt;               &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          
##  1 &lt;split [31.3K/3.5K]&gt; Fold01 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  2 &lt;split [31.3K/3.5K]&gt; Fold02 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  3 &lt;split [31.3K/3.5K]&gt; Fold03 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  4 &lt;split [31.3K/3.5K]&gt; Fold04 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  5 &lt;split [31.3K/3.5K]&gt; Fold05 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  6 &lt;split [31.3K/3.5K]&gt; Fold06 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  7 &lt;split [31.3K/3.5K]&gt; Fold07 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  8 &lt;split [31.3K/3.5K]&gt; Fold08 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  9 &lt;split [31.3K/3.5K]&gt; Fold09 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
## 10 &lt;split [31.3K/3.5K]&gt; Fold10 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
```

---
# Check out evaluation metrics


```r
m1_metrics &lt;- m1 %&gt;% 
  select(id, .metrics) %&gt;% 
  unnest(.metrics) %&gt;% 
  pivot_wider(names_from = .metric, 
              values_from = .estimate)

m1_metrics
```

```
## # A tibble: 10 x 4
##    id     .estimator     rmse        rsq
##    &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;
##  1 Fold01 standard   110.5284 0.08974218
##  2 Fold02 standard   109.1003 0.09944144
##  3 Fold03 standard   109.0673 0.09026434
##  4 Fold04 standard   110.7102 0.09914319
##  5 Fold05 standard   108.9379 0.09960492
##  6 Fold06 standard   109.8719 0.08570393
##  7 Fold07 standard   108.1554 0.08931543
##  8 Fold08 standard   108.8401 0.1072132 
##  9 Fold09 standard   108.6262 0.1020824 
## 10 Fold10 standard   112.1286 0.1068249
```

.footnote[Note that the model results were not actually saved]

---
# Fit a second model
### Include interaction

* Recipe gets a bit more complicated here. 


```r
interaction_rec &lt;- recipe(score ~ gndr + sp_ed_fg, train) %&gt;% 
  step_dummy(all_predictors()) %&gt;% 
  step_interact(terms = ~ starts_with("gndr"):starts_with("sp_ed_fg"))
interaction_rec
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          2
## 
## Operations:
## 
## Dummy variables from all_predictors
## Interactions with starts_with("gndr"):starts_with("sp_ed_fg")
```

---
# Fit the model


```r
m2 &lt;- mod %&gt;% 
  fit_resamples(interaction_rec, cv)
m2
```

```
## #  10-fold cross-validation using stratification 
## # A tibble: 10 x 4
##    splits               id     .metrics         .notes          
##    &lt;list&gt;               &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          
##  1 &lt;split [31.3K/3.5K]&gt; Fold01 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  2 &lt;split [31.3K/3.5K]&gt; Fold02 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  3 &lt;split [31.3K/3.5K]&gt; Fold03 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  4 &lt;split [31.3K/3.5K]&gt; Fold04 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  5 &lt;split [31.3K/3.5K]&gt; Fold05 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  6 &lt;split [31.3K/3.5K]&gt; Fold06 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  7 &lt;split [31.3K/3.5K]&gt; Fold07 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  8 &lt;split [31.3K/3.5K]&gt; Fold08 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  9 &lt;split [31.3K/3.5K]&gt; Fold09 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
## 10 &lt;split [31.3K/3.5K]&gt; Fold10 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
```


---
# Check evaluation metrics again


```r
m2_metrics &lt;- m2 %&gt;% 
  select(id, .metrics) %&gt;% 
  unnest(.metrics) %&gt;% 
  pivot_wider(names_from = .metric, 
              values_from = .estimate)

m2_metrics
```

```
## # A tibble: 10 x 4
##    id     .estimator     rmse        rsq
##    &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;
##  1 Fold01 standard   110.5301 0.08973596
##  2 Fold02 standard   109.0852 0.09969244
##  3 Fold03 standard   109.0596 0.09038034
##  4 Fold04 standard   110.6956 0.09938052
##  5 Fold05 standard   108.9510 0.09937968
##  6 Fold06 standard   109.8492 0.08608010
##  7 Fold07 standard   108.1676 0.08917341
##  8 Fold08 standard   108.8173 0.1076011 
##  9 Fold09 standard   108.5917 0.1026804 
## 10 Fold10 standard   112.0840 0.1075691
```


---
# Join metrics


```r
metrics_joined &lt;- left_join(m1_metrics, m2_metrics, 
          by = c("id", ".estimator"),
          suffix = c("_m1", "_m2"))

metrics_joined
```

```
## # A tibble: 10 x 6
##    id     .estimator  rmse_m1     rsq_m1  rmse_m2     rsq_m2
##    &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;
##  1 Fold01 standard   110.5284 0.08974218 110.5301 0.08973596
##  2 Fold02 standard   109.1003 0.09944144 109.0852 0.09969244
##  3 Fold03 standard   109.0673 0.09026434 109.0596 0.09038034
##  4 Fold04 standard   110.7102 0.09914319 110.6956 0.09938052
##  5 Fold05 standard   108.9379 0.09960492 108.9510 0.09937968
##  6 Fold06 standard   109.8719 0.08570393 109.8492 0.08608010
##  7 Fold07 standard   108.1554 0.08931543 108.1676 0.08917341
##  8 Fold08 standard   108.8401 0.1072132  108.8173 0.1076011 
##  9 Fold09 standard   108.6262 0.1020824  108.5917 0.1026804 
## 10 Fold10 standard   112.1286 0.1068249  112.0840 0.1075691
```

---
# Interaction worth it?
### Move back to long

```r
metrics &lt;- metrics_joined %&gt;% 
  pivot_longer(cols = contains("_"),
               names_to = c("metric", "model"),
               values_to = "estimate",
               names_sep = "_")
metrics
```

```
## # A tibble: 40 x 5
##    id     .estimator metric model     estimate
##    &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;        &lt;dbl&gt;
##  1 Fold01 standard   rmse   m1    110.5284    
##  2 Fold01 standard   rsq    m1      0.08974218
##  3 Fold01 standard   rmse   m2    110.5301    
##  4 Fold01 standard   rsq    m2      0.08973596
##  5 Fold02 standard   rmse   m1    109.1003    
##  6 Fold02 standard   rsq    m1      0.09944144
##  7 Fold02 standard   rmse   m2    109.0852    
##  8 Fold02 standard   rsq    m2      0.09969244
##  9 Fold03 standard   rmse   m1    109.0673    
## 10 Fold03 standard   rsq    m1      0.09026434
## # â€¦ with 30 more rows
```

---
# Inspect by RMSE


```r
metrics %&gt;% 
  filter(metric == "rmse") %&gt;% 
  group_by(id) %&gt;% 
  summarize(estimate = min(estimate)) 
```

```
## # A tibble: 10 x 2
##    id     estimate
##    &lt;chr&gt;     &lt;dbl&gt;
##  1 Fold01 110.5284
##  2 Fold02 109.0852
##  3 Fold03 109.0596
##  4 Fold04 110.6956
##  5 Fold05 108.9379
##  6 Fold06 109.8492
##  7 Fold07 108.1554
##  8 Fold08 108.8173
##  9 Fold09 108.5917
## 10 Fold10 112.0840
```

---


```r
metrics %&gt;% 
  filter(metric == "rmse") %&gt;% 
  group_by(id) %&gt;% 
  summarize(estimate = min(estimate)) %&gt;% 
* semi_join(metrics, .)
```

```
## # A tibble: 10 x 5
##    id     .estimator metric model estimate
##    &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;
##  1 Fold01 standard   rmse   m1    110.5284
##  2 Fold02 standard   rmse   m2    109.0852
##  3 Fold03 standard   rmse   m2    109.0596
##  4 Fold04 standard   rmse   m2    110.6956
##  5 Fold05 standard   rmse   m1    108.9379
##  6 Fold06 standard   rmse   m2    109.8492
##  7 Fold07 standard   rmse   m1    108.1554
##  8 Fold08 standard   rmse   m2    108.8173
##  9 Fold09 standard   rmse   m2    108.5917
## 10 Fold10 standard   rmse   m2    112.0840
```


---

```r
metrics %&gt;% 
  filter(metric == "rmse") %&gt;% 
  group_by(id) %&gt;% 
  summarize(estimate = min(estimate)) %&gt;% 
  semi_join(metrics, .) %&gt;% 
* count(model)
```

```
## # A tibble: 2 x 2
##   model     n
##   &lt;chr&gt; &lt;int&gt;
## 1 m1        3
## 2 m2        7
```


--
### Answer: ðŸ¤·


---
# Alternative way to think about it


```r
metrics_joined %&gt;% 
  mutate(rmse_diff = round(rmse_m1 - rmse_m2, 3),
         rsq_diff  = round(rsq_m1 - rsq_m2, 3)) %&gt;% 
  select(id, ends_with("diff"))
```

```
## # A tibble: 10 x 3
##    id     rmse_diff rsq_diff
##    &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;
##  1 Fold01    -0.002    0    
##  2 Fold02     0.015    0    
##  3 Fold03     0.008    0    
##  4 Fold04     0.015    0    
##  5 Fold05    -0.013    0    
##  6 Fold06     0.023    0    
##  7 Fold07    -0.012    0    
##  8 Fold08     0.023    0    
##  9 Fold09     0.034   -0.001
## 10 Fold10     0.045   -0.001
```

--
### Conclusion: Probs not

---
# Variable importance

* Another way to think about this is how .b[important] specific variables, interactions, or other features of the model are to the estimated predictive accuracy


--

.center[
![](https://koalaverse.github.io/vip/reference/figures/logo-vip.png)
]

---
# VIP
* `vip::vip`: Create a `v`ariable `i`mportance `p`lot
* `vip::vi`: Estimate `v`ariable `i`mportance (numbers)

--

```r
library(vip)
m &lt;- lm(score ~ gndr + sp_ed_fg + gndr:sp_ed_fg, data = train)
vi(m)
```

```
## # A tibble: 3 x 3
##   Variable        Importance Sign 
##   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;
## 1 sp_ed_fgY        39.68590  NEG  
## 2 gndrM:sp_ed_fgY   3.086095 POS  
## 3 gndrM             2.129051 POS
```

---
# Graphically

```r
vip(m)
```

![](w3p1-var-select-model-perf_files/figure-html/vip1-1.png)&lt;!-- --&gt;

---
# How to improve this model
* I've approached this from a (light) theoretical variable-inclusion perspective

  + Hopefully you have domain knowledge in your application that allows you to start from a meaningful place.
  
  + Other variables that theoretically relate that we could start with (e.g., grade level, economic disadvantage status)
 

--
* What if I didn't know? We could start out by looking at all variables, and choosing the most important


--


```r
vip_1a &lt;- vip(lm(score ~ ., train))
```

---

```r
vip_1a
```

![](w3p1-var-select-model-perf_files/figure-html/show-vip2-1.png)&lt;!-- --&gt;


--

This basically tells us that outside of sped (which we've included already) gifted/talented (tag), economic disadvantage, test date, and ethnic code are important predictors. Let's look a bit deeper.

---
# Numerically

```r
vip_1b &lt;- vi(lm(score ~ ., train))
vip_1b
```

```
## # A tibble: 46 x 3
##    Variable     Importance Sign 
##    &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;
##  1 tag_ed_fgY    58.28341  POS  
##  2 sp_ed_fgY     56.30205  NEG  
##  3 econ_dsvntgY  37.98245  NEG  
##  4 ethnic_cdB    23.01783  NEG  
##  5 ethnic_cdH    19.56920  NEG  
##  6 tst_dt        16.42276  POS  
##  7 ethnic_cdW    13.51227  NEG  
##  8 ethnic_cdM    12.12659  NEG  
##  9 ethnic_cdI    11.52878  NEG  
## 10 ethnic_cdP     9.675022 NEG  
## # â€¦ with 36 more rows
```


---
# Interactions
You can also use vip with interactions


```r
vip_2a &lt;- vip(lm(score ~ .^2, train))
vip_2a
```

![](w3p1-var-select-model-perf_files/figure-html/vip2a-1.png)&lt;!-- --&gt;

---
# New model


```r
post_vip_rec &lt;- recipe(score ~ tag_ed_fg + sp_ed_fg + econ_dsvntg +
                               tst_dt + ethnic_cd, 
                       data = train)

m3 &lt;- mod %&gt;% 
  fit_resamples(post_vip_rec, cv)

m3
```

```
## #  10-fold cross-validation using stratification 
## # A tibble: 10 x 4
##    splits               id     .metrics         .notes          
##    &lt;list&gt;               &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          
##  1 &lt;split [31.3K/3.5K]&gt; Fold01 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  2 &lt;split [31.3K/3.5K]&gt; Fold02 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  3 &lt;split [31.3K/3.5K]&gt; Fold03 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  4 &lt;split [31.3K/3.5K]&gt; Fold04 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  5 &lt;split [31.3K/3.5K]&gt; Fold05 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  6 &lt;split [31.3K/3.5K]&gt; Fold06 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  7 &lt;split [31.3K/3.5K]&gt; Fold07 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  8 &lt;split [31.3K/3.5K]&gt; Fold08 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
##  9 &lt;split [31.3K/3.5K]&gt; Fold09 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
## 10 &lt;split [31.3K/3.5K]&gt; Fold10 &lt;tibble [2 Ã— 3]&gt; &lt;tibble [0 Ã— 1]&gt;
```


---
# M3 metrics


```r
m3 %&gt;% 
  select(id, .metrics) %&gt;% 
  unnest(.metrics) %&gt;% 
  pivot_wider(names_from = .metric, 
              values_from = .estimate)
```

```
## # A tibble: 10 x 4
##    id     .estimator     rmse       rsq
##    &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;
##  1 Fold01 standard   97.32035 0.2940837
##  2 Fold02 standard   96.40935 0.2968018
##  3 Fold03 standard   97.26262 0.2763919
##  4 Fold04 standard   98.65282 0.2846609
##  5 Fold05 standard   97.17828 0.2834393
##  6 Fold06 standard   97.69099 0.2771417
##  7 Fold07 standard   95.94327 0.2830697
##  8 Fold08 standard   97.73500 0.2799697
##  9 Fold09 standard   98.31399 0.2654712
## 10 Fold10 standard   99.12599 0.3028104
```

---
## Improving model performance further
* Other variables? (e.g., grade level)

* Interactions?
  + `step_interact`

* Nonlinearity?
  + `step_poly`


--
### Refining the model
* We have quite a bit of repeated code here. If this were the strategy we were using, we'd probably want to write functions for the model comparisons.


---
# How are we doing on time?
### Skip if not enough time, otherwise...

Try to refine this model further to boost model performance more! Consider modifications listed in previous slide (inclusion of other variables, nonlinear terms, or interactions)

<div class="countdown" id="timer_5e91d010" style="top:0.5;right:0.5;bottom:0.5;left:0.75;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
# Evaluation on test set
* Note we wouldn't usually jump to this point yet, but let's try.


--
### First
Fit model to full training data


--
### First first
Apply our recipe to the full training data


```r
train_prepped &lt;- post_vip_rec %&gt;% 
  prep() %&gt;% 
  juice()
```

---

```r
train_prepped
```

```
## # A tibble: 34,818 x 6
##    tag_ed_fg sp_ed_fg econ_dsvntg tst_dt     ethnic_cd score
##    &lt;fct&gt;     &lt;fct&gt;    &lt;fct&gt;       &lt;date&gt;     &lt;fct&gt;     &lt;dbl&gt;
##  1 N         N        N           2018-05-23 W          2560
##  2 N         N        Y           2018-04-23 H          2299
##  3 N         Y        Y           2018-05-16 W          2453
##  4 N         N        Y           2018-05-15 H          2367
##  5 N         N        N           2018-04-26 H          2607
##  6 N         N        Y           2018-05-21 M          2553
##  7 N         Y        Y           2018-05-15 W          2396
##  8 N         Y        N           2018-05-23 W          2404
##  9 N         N        Y           2018-05-30 W          2579
## 10 N         N        N           2018-05-31 W          2590
## # â€¦ with 34,808 more rows
```

---
# Fit to full train

```r
test_mod &lt;- mod %&gt;% 
  fit(score ~ ., 
      data = train_prepped) 
```

--
### Next: Extract test dataset


```r
test &lt;- testing(splt)
test
```

```
## # A tibble: 11,605 x 35
##        id gndr  ethnic_cd attnd_dist_inst_id attnd_schl_inst_id enrl_grd
##     &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                  &lt;dbl&gt;              &lt;dbl&gt;    &lt;dbl&gt;
##  1 182007 M     H                       2142                751        4
##  2 219059 F     H                       2048               5205        3
##  3 139302 F     M                       2054                441        6
##  4 191166 M     H                       2256               4639        3
##  5  40916 M     M                       2239               1148        4
##  6 217476 M     W                       2142                740        3
##  7 146634 F     H                       2183                933        5
##  8 224206 F     W                       2244               4730        3
##  9  29278 M     M                       2082                518        8
## 10 214204 F     I                       2056                465        3
## # â€¦ with 11,595 more rows, and 29 more variables: tst_bnch &lt;chr&gt;,
## #   tst_dt &lt;date&gt;, migrant_ed_fg &lt;chr&gt;, ind_ed_fg &lt;chr&gt;, sp_ed_fg &lt;chr&gt;,
## #   tag_ed_fg &lt;chr&gt;, econ_dsvntg &lt;chr&gt;, ayp_lep &lt;chr&gt;, stay_in_dist &lt;chr&gt;,
## #   stay_in_schl &lt;chr&gt;, dist_sped &lt;chr&gt;, trgt_assist_fg &lt;chr&gt;,
## #   ayp_schl_partic &lt;chr&gt;, ayp_dist_prfrm &lt;chr&gt;, ayp_schl_prfrm &lt;chr&gt;,
## #   rc_schl_partic &lt;chr&gt;, rc_dist_prfrm &lt;chr&gt;, rc_schl_prfrm &lt;chr&gt;,
## #   partic_dist_inst_id &lt;dbl&gt;, partic_schl_inst_id &lt;dbl&gt;, lang_cd &lt;chr&gt;,
## #   tst_atmpt_fg &lt;chr&gt;, grp_rpt_schl_partic &lt;chr&gt;, grp_rpt_dist_prfrm &lt;chr&gt;,
## #   grp_rpt_schl_prfrm &lt;chr&gt;, score &lt;dbl&gt;, ncessch &lt;dbl&gt;, lat &lt;dbl&gt;, lon &lt;dbl&gt;
```

---
# Prepare test dataset


```r
# Apply recipe to test dataset
test_prepped &lt;- post_vip_rec %&gt;% 
  prep() %&gt;% 
* bake(test)

test_prepped
```

```
## # A tibble: 11,605 x 6
##    tag_ed_fg sp_ed_fg econ_dsvntg tst_dt     ethnic_cd score
##    &lt;fct&gt;     &lt;fct&gt;    &lt;fct&gt;       &lt;date&gt;     &lt;fct&gt;     &lt;dbl&gt;
##  1 N         Y        Y           2018-05-10 H          2430
##  2 N         N        Y           2018-05-24 H          2326
##  3 N         N        Y           2018-05-17 M          2435
##  4 N         Y        Y           2018-05-30 H          2395
##  5 Y         N        N           2018-05-18 M          2658
##  6 N         N        Y           2018-05-11 W          2351
##  7 N         N        Y           2018-05-16 H          2393
##  8 N         N        N           2018-05-23 W          2502
##  9 N         N        N           2018-05-22 M          2192
## 10 N         N        Y           2018-05-09 I          2325
## # â€¦ with 11,595 more rows
```

---
# Make predictions


```r
preds &lt;- test_prepped %&gt;% 
  mutate(estimate = predict(test_mod$fit, newdata = .)) %&gt;% 
  select(truth = score, estimate)
preds
```

```
## # A tibble: 11,605 x 2
##    truth estimate
##    &lt;dbl&gt;    &lt;dbl&gt;
##  1  2430 2364.985
##  2  2326 2461.778
##  3  2435 2487.387
##  4  2395 2375.315
##  5  2658 2666.598
##  6  2351 2488.350
##  7  2393 2457.646
##  8  2502 2544.793
##  9  2192 2540.215
## 10  2325 2458.488
## # â€¦ with 11,595 more rows
```

---
# Evaluate prediction


```r
bind_rows(
  rmse(preds, truth, estimate),
  rsq(preds, truth, estimate)
)
```

```
## # A tibble: 2 x 3
##   .metric .estimator  .estimate
##   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;
## 1 rmse    standard   96.87855  
## 2 rsq     standard    0.2841366
```

---
class: inverse center middle

# Evaluation metrics
### Quickly

---
# Big picture
* We've spent most of today talking about the process of building a linear model. But how you determine what is "best" depends (in part) on your evaluation metric.

--

.Large[.center[For regression problems]]

--

.pull-left[
### Well known metrics

* MSE - mean square error
* RMSE - root mean square error
* `\(R^2\)`
]

--

.pull-right[
### Less well-known metrics
* MAE - mean absolute error
* RPIQ - ratio of performance to inter-quartile
* Huber loss - balances MSE and MAE
]

--

see [yardstick documentation](https://tidymodels.github.io/yardstick/reference/index.html) for complete reference of metrics implemented.

---
# A few notes

* RMSE is the mean error, but on the scale of the outcome
  + .b[Pros]: Generally fairly interpretable - how much are your predictions off by, on average?
  + .r[Cons]: The mean (generally) can be susceptible to outliers


--
* MAE is the median error
  + .b[Pros]: Less influenced by outliers
  + .r[Cons]: Somewhat less familiar; sometimes the outlier cases are highly important


--
* Huber Loss balances (R)MSE and MAE
  + Quadratic for small residual values, linear for large residual values
  + .b[Pros]: Sensitivity of RMSE with robustness of MAE
  + .r[Cons]: Less familiar and interpretable; does not translate to common measure of central tenancy

---
# Huber loss 
Compared to .b[squared errors]

.center[

&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Huber_loss.svg/1920px-Huber_loss.svg.png" height="400px" /&gt;

]

---
# Overall takeaway
* There are more metrics than described above.

--
* Choosing a metric can be really important, and often is driven by the specific problem

.g[(Example from handwriting recognition algorithm)]


--
* We haven't talked about classification yet, but there are similarly many different evaluation metrics there


--
* We'll try to incorporate a discussion of these as we go along

---
# Kaggle
### Moving back to our model
* What do we need to do to make predictions from this model for kaggle?


--
* Preprocess the `train.csv` using the recipe we used above (particularly if you have interactions, polynomial terms, etc.)


--
* Fit the model to the preprocessed data


--
* Make predictions
  
  + Will we be able to evaluate?
  

--
* Upload a csv file that has a `Id` and `Predicted` columns. 


---
class: inverse center middle

# Next time
### Lab 2
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "atelier-dune-light",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
